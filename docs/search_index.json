[
["index.html", "Fisheries Catch Forecasting Preface", " Fisheries Catch Forecasting Elizabeth Holmes 2020-10-02 Preface This book will show you how to use R to model and forecast catch time series using a variety of standard forecasting models. Time-varying regression Box-Jenkins (ARIMA) models Exponential smoothing Multivaritate regression with ARMA errors ARMA models with covariates (ARMAX) Seasonal ARIMA models Seasonal exponential smoothing models In addition to model fitting, model diagnostics, forecast diagnostics and accuracy metrics will be covered along with uncertainty metrics. The focus of this book is on analysis of univariate time series. However multivariate regression with autocorrelated errors and multivariate autoregressive models (MAR) will be covered more briefly. For an indepth discussion of multivariate autoregressive models and multivariate autoregressive state-space models, see Holmes, Ward and Scheuerell (2018). As a work of the United States government, this project is in the public domain within the United States of America. Additionally, we waive copyright and related rights in the work worldwide through the Unlicense public domain dedication. Unlicense public domain dedication. "],
["1-introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction There are many approaches for forecasting from time series alone–meaning without any covariates or exogenous variables. Examples are the approaches used in the following papers. Stergiou and Christou 1996 Time-varying regression Box-Jenkins models, aka ARIMA models Multivariate time-series approaches Harmonic regression Dynamic regression Vector autoregression (MAR) Exponential smoothing (2 variants) Exponential surplus yield model (FOX) Georgakarakos et al. 2006 Box-Jenkins models, aka ARIMA models Artificial neural networks (ANNs) Bayesian dynamic models Lawer 2016 Box-Jenkins models, aka ARIMA models Artificial neural networks (ANNs) Exponential Smoothing (6 variants) This course will focus on three of these methods: time-varying regression, ARIMA models and Exponential smoothing models. These will be shown with and without seasonality. Methods which use covariates, or exogenous variables, will also be addressed.\n"],
["1-1-stergiou-and-christou-1996.html", "1.1 Stergiou and Christou 1996", " 1.1 Stergiou and Christou 1996 These three methods will be demonstrated by replicating the work in Stergiou and Christou (1996) Modelling and forecasting annual fisheries catches: comparison of regression, univariate and multivariate time series methods. Fisheries Research 25: 105-136. 1.1.1 Hellenic landings data We will use the annual landings data from Hellenic (Greek) waters (Figure 1.1) that were used in Stergiou and Christou (1996). Stergiou and Christou analyzed 16 species. We will look at just two of the species: Anchovy and Sardine. Stergiou and Christou used the data from 1964-1989. We have the data up to 2007, but will focus mainly on 1964-1989 (the first half of the time series) to replicate Stergiou and Christou’s analyses. Figure 1.1: Location of the fishery. The data are available in tables in yearly fishery survey reports published by the Hellenic Statisical Authority. The main landings data is in Table IV in these reports. "],
["1-2-the-landings-data-and-covariates.html", "1.2 The landings data and covariates", " 1.2 The landings data and covariates The FishForecast package has the following data objects: greeklandings The 1964 to 2007 total landings data multiple species. It is stored as a data frame, not ts object, with a year column, a species column and columns for landings in metric tons and log metric tons. anchovy and sardine A data frame for the landings (in log metric tons) of these species. These are the example catch time series used in the chapters. The data are 1964-2007, however Stergiou and Christou used 1964-1989 and the time series are subsetted to this time period for the examples. These data frames have only year and log.metric.tons columns. anchovyts and sardinets A ts object for the yearly landings (in log metric tons) of these species. anchovy87 and sardine87 A subsetted data frame with Year &lt;= 1987. This is the training data used in Stergiou and Christou. anchovy87ts and sardine87ts A ts object for the yearly landings (in log metric tons) of these species for 1964-1987. ecovsmean.mon and ecovsmean.year The environmental covariates air temperature, pressure, sea surface temperature, vertical wind, and wind speed cubed average monthly and yearly over three 1 degree boxes in the study area. See the chapter on covariates for details. greekfish.cov The fisheries covariates on number of boats, horsepower, and fishers. Load the data by loading the FishForecast package and use only the 1964-1989 landings. We use subset() to subset the landings data frame. Not window() as that is a function for subsetting ts objects. require(FishForecast) ## Loading required package: FishForecast landings89 = subset(greeklandings, Year &lt;= 1989) ggplot(landings89, aes(x=Year, y=log.metric.tons)) + geom_line() + facet_wrap(~Species) "],
["1-3-ts-objects.html", "1.3 ts objects", " 1.3 ts objects A ts object in R is a time series, univariate or multivariate, that has information on the major time step value (e.g. year) and the period of the minor time step, if any. For example, if your data are monthly then the major time step is year, the minor time step is month and the period is 12 (12 months a year). If you have daily data collected hourly then you major time step is day, minor time step is hour and period is 24 (24 hours per day). If you have yearly data collected yearly, your major time step is year, your minor time step is also year, and the period is 1 (1 year per year). You cannot have multiple minor time steps, for example monthly data collected hourly with daily and hourly periods specified. The data in a ts object cannot have any missing time steps. For example, if your data were in a data frame with a column for year, you could have a missing year, say no row for year 1988, and the data sense would still ‘make sense’. The data in a ts object cannot have any missing ‘rows’. If there is no data for a particular year or year/month (if your data are monthly), then that data point must be entered as a NA. You do not need a time step (e.g. year/month) column(s) for a ts object. You only need the starting major time step and the starting minor time step (if not 1) and the period. All the time values from each data point can be computed from those 2 pieces of information if there are no gaps in your time series. Missing data are fine; they just have to be entered with a NA. All the non-seasonal examples shown will work on a plain vector of numbers, and it it is not necessary to convert a non-seasonal time series into a ts object. That said, if you do not convert to a ts object, you will miss out on all the plotting and subsetting functions that are written for ts objects. Also when you do multivariate regression with covariates, having your data and covariates stored as a ts object will make regressing against lagged covariates (covariate values in the past) easier. 1.3.1 ts() function To convert a vector of numbers to a ts object, we use the ts() function. ts(data = NA, start = 1, end = numeric(), frequency = 1) start is a two number vector with the first major time step and the first minor time step. If you only pass in one number, then it will use 1 (first minor time step) as the 2nd number in start. end is specified in exactly the same way and you only need to specified start or end, not both. frequency is the number of minor time steps per major time step. If you do not pass this in, it will assume that frequency=1, i.e. no periods or season in your data. If you specify frequency=4, it will assume that the period is quarterly. If you specify that frequency=12, it will assume that period is monthly. This just affects the labeling of the minor time step columns and will print your data with 4 or 12 columns. For other frequencies, the data will not be printed with columns for the minor time steps, but the information is there and plotting will use the major steps. Examples Quarterly data aa &lt;- ts(1:24, start=c(1960,1), frequency=4) aa ## Qtr1 Qtr2 Qtr3 Qtr4 ## 1960 1 2 3 4 ## 1961 5 6 7 8 ## 1962 9 10 11 12 ## 1963 13 14 15 16 ## 1964 17 18 19 20 ## 1965 21 22 23 24 plot(aa, type=&quot;p&quot;) Monthly data aa &lt;- ts(1:24, start=c(1960,1), frequency=12) aa ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 1960 1 2 3 4 5 6 7 8 9 10 11 12 ## 1961 13 14 15 16 17 18 19 20 21 22 23 24 plot(aa, type=&quot;p&quot;) Biennial data aa &lt;- ts(1:24, start=c(1960,1), frequency=2) aa ## Time Series: ## Start = c(1960, 1) ## End = c(1971, 2) ## Frequency = 2 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 plot(aa, type=&quot;p&quot;) 1.3.2 ggplot and ts objects In some ways, plotting ts object is easy. Just use plot() or autoplot() and it takes care of the time axis. In other ways, it can be frustrating if you want to alter the defaults. autoplot() autoplot() is a ggplot of the ts object. aa &lt;- ts(1:24, start=c(1960,1), frequency=12) autoplot(aa) and you have access to the usual gglot functions. autoplot(aa) + geom_point() + ylab(&quot;landings&quot;) + xlab(&quot;&quot;) + ggtitle(&quot;Anchovy landings&quot;) Adding minor tick marks in ggplot is tedious (google if you want that) but adding vertical lines at your minor ticks is easy. aa &lt;- ts(1:24, start=c(1960,1), frequency=12) vline_breaks &lt;- seq(1960, 1962, by=1/12) autoplot(aa) + geom_vline(xintercept = vline_breaks, color =&quot;blue&quot;) + geom_point() 1.3.3 Plotting using a data frame Often it is easier to work with a data frame (or a tibble) with columns for your major and minor time steps. That way you are not locked into whatever choices the plotting and printing functions use for ts objects. Many plotting functions work nicely with this type of data frame and you have full control over plotting and summarizing your data. To plot the x-axis, we need to add a date column in date format. Knowing the right format to use for as.Date() will take some sleuthing on the internet. The default is 1960-12-31 so if you get stuff you can always write your date in that format and use the default. Here I use 1960Jan01 and specify the format for that. I have used the date_format() function in the scales package to help format the dates on the x-axis. aa &lt;- data.frame( year=rep(1960:1961,each=12), month = rep(month.abb,2), val=1:24) aa$date &lt;- as.Date(paste0(aa$year,aa$month,&quot;01&quot;),&quot;%Y%b%d&quot;) ggplot(aa, aes(x=date, y=val)) + geom_point() + scale_x_date(labels=scales::date_format(&quot;%b-%Y&quot;)) + ylab(&quot;landings&quot;) + xlab(&quot;&quot;) "],
["1-4-packages.html", "1.4 Packages", " 1.4 Packages We will be mainly be using the forecast (Hyndman et al. 2020) and tseries (Trapletti and Hornik 2019) packages, with the MARSS (Holmes et al. 2020) package to implement ARMAX models. However we will also use a variety of other packages especially for the multivariate regression chapter. So that you can keep track of what package a function come from, I will use the :: notation for functions that are not from the following standard packages: base R stats ggplot2 Thus to call function fun1 from package pack1, I will use pack1::fun1(). This will make the code more verbose but you will be able to keep track of which function comes from what package. To install the data used in this book along with all the needed packages, install the FishForecast package from GitHub. If you are on a Windows machine, you will need to install Rtools in order to install packages from GitHub. To install a package from GitHub, install the devtools package and then run library(devtools) devtools::install_github(&quot;Fish-Forecast/FishForecast&quot;) Calling library(FishForecast) will then make the data objects available. tidyverse and piping I will minimize the use of tidyverse and piping. Although the latter can create much more concise code, for beginner R users and programmers, I think it will interfere with learning. I may add the piped versions of the code later. I am not going to be doing much ‘data-wrangling’. I will assume that your data are in the tidyverse format, though I will not be using tibbles explicitly. Our data are quite simple, so this is not hard. See the chapter on inputting your data. plotting packages I will use a combination of base plotting and ggplot2 (Wickham et al. 2020) plotting. Doing a tutorial on basic plotting with ggplot2 may be helpful for the material. "],
["1-5-references.html", "1.5 References", " 1.5 References We will be using classic methods for catch forecasting discussed in the following reference papers: We are replicating the work in (Stergiou and Christou 1996) (Link). These methods are also discussed in (Lawer 2016) (PDF). And in (Georgakarakos, Doutsoubas, and Valavanis 2006) (Link). A PDF reprint is available on the Hellenic Center for Marine Research website. The chapter on modeling seasonal catch data will use models discussed in (Stergiou, Christou, and Petrakis 1997) (Link). See their ResearchGate page for a PDF reprint. "],
["2-time-varying-regression.html", "Chapter 2 Time-varying regression", " Chapter 2 Time-varying regression Time-varying regression is simply a linear regression where time is the explanatory variable: \\[log(catch) = \\alpha + \\beta t + \\beta_2 t^2 + \\dots + e_t\\] The error term ( \\(e_t\\) ) was treated as an independent Normal error ( \\(\\sim N(0, \\sigma)\\) ) in Stergiou and Christou (1996). If that is not a reasonable assumption, then it is simple to fit a non-Gausian error model in R. Order of the time polynomial The order of the polynomial of \\(t\\) determines how the time axis (x-axis) relates to the overall trend in the data. A 1st order polynomial (\\(\\beta t\\)) will allow a linear relationship only. A 2nd order polynomial(\\(\\beta_1 t + \\beta_2 t^2\\)) will allow a convex or concave relationship with one peak. 3rd and 4th orders will allow more flexible relationships with more peaks. "],
["2-1-fitting.html", "2.1 Fitting", " 2.1 Fitting Fitting a time-varying regression is done with the lm() function. For example, here is how to fit a 4th-order polynomial for time to the anchovy data. We are fitting this model: \\[log(Anchovy) = \\alpha + \\beta t + \\beta_2 t^2 + \\beta_3 t^3 + \\beta_4 t^4 + e_t\\] First load in the data by loading the FishForecast package. anchovy is a data frame with year and log.metric.tons columns. anchovy87 is the same data frame but with the years 1964 to 1987. These are the years that Stergio and Christou use for fitting their models. They hold out 1988 and 1989 for forecast evaluation. require(FishForecast) We need to add on a column for \\(t\\) (and \\(t^2\\), \\(t^3\\), \\(t^4\\)) where the first year is \\(t=1\\). We could regress against year (so 1964 to 1987), but by convention, one regresses against 1 to the number of years or 0 to the number of years minus 1. Stergiou and Christou did the former. anchovy87$t = anchovy87$Year-1963 anchovy87$t2 = anchovy87$t^2 anchovy87$t3 = anchovy87$t^3 anchovy87$t4 = anchovy87$t^4 model &lt;- lm(log.metric.tons ~ t + t2 + t3 + t4, data=anchovy87) All our covariates are functions of \\(t\\), so we do not actually need to add on the \\(t^2\\), \\(t^3\\) and \\(t^4\\) to our data frame. We can use the I() function. This function is useful whenever you want to use a transformed value of a column of your data frame in your regression. anchovy87$t = anchovy87$Year-1963 model &lt;- lm(log.metric.tons ~ t + I(t^2) + I(t^3) + I(t^4), data=anchovy87) Let’s look at the fit. summary(model) ## ## Call: ## lm(formula = log.metric.tons ~ t + I(t^2) + I(t^3) + I(t^4), ## data = anchovy87) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.26951 -0.09922 -0.01018 0.11777 0.20006 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.300e+00 1.953e-01 42.498 &lt;2e-16 *** ## t 1.751e-01 1.035e-01 1.692 0.107 ## I(t^2) -2.182e-02 1.636e-02 -1.333 0.198 ## I(t^3) 1.183e-03 9.739e-04 1.215 0.239 ## I(t^4) -1.881e-05 1.934e-05 -0.972 0.343 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1458 on 19 degrees of freedom ## Multiple R-squared: 0.9143,\tAdjusted R-squared: 0.8962 ## F-statistic: 50.65 on 4 and 19 DF, p-value: 7.096e-10 2.1.1 Orthogonal polynomials None of the time effects are significant despite an obvious linear temporal trend to the data. What’s going on? Well \\(t\\), \\(t^2\\), \\(t^3\\) and \\(t^4\\) are all highly correlated. Fitting a linear regression with multiple highly correlated covariates will not get you anywhere unless perhaps all the covariates are needed to explain the data. We will see the latter case for the sardine. In the anchovy case, multiple of the covariates could explain the linear-ish trend. You could try fitting the first degree model \\(x_t = \\alpha + \\beta t + e_t\\), then the second \\(x_t = \\alpha + \\beta_1 t + \\beta_2 t^2 + e_t\\), then the third. This would reveal that in the first and second order fits, we get significant effects of time in our model. However the correct way to do this would be to use orthogonal polynomials. poly() function The poly() function creates orthogonal covariates for your polynomial. What does that mean? Let’s say you want to fit a model with a 2nd order polynomial of \\(t\\). It has \\(t\\) and \\(t^2\\), but using these as covariates directly lead to using two covariates that are highly correlated. Instead we want a covariate that explains \\(t\\) and another that explains the part of \\(t^2\\) that cannot be explained by \\(t\\). poly() creates these orthogonal covariates. The poly() function creates covariates with mean zero and identical variances. Covariates with different means and variances makes it hard to compare the estimated effect sizes. T1 = 1:24; T2=T1^2 c(mean(T1),mean(T2),cov(T1, T2)) ## [1] 12.5000 204.1667 1250.0000 T1 = poly(T1,2)[,1]; T2=poly(T1,2)[,2] c(mean(T1),mean(T2),cov(T1, T2)) ## [1] 4.921826e-18 2.674139e-17 -4.949619e-20 Using poly() to fit the anchovy data We saw in the anchovy fit that using \\(t\\), \\(t^2\\), \\(t^3\\) and \\(t^4\\) directly in the fit resulted in no significant estimated time effect despite a clear temporal trend in the data. If we fit with poly() so that we do not use correlated time covariates, we see a different picture. model &lt;- lm(log.metric.tons ~ poly(t,4), data=anchovy87) summary(model) ## ## Call: ## lm(formula = log.metric.tons ~ poly(t, 4), data = anchovy87) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.26951 -0.09922 -0.01018 0.11777 0.20006 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.08880 0.02976 305.373 &lt; 2e-16 *** ## poly(t, 4)1 1.97330 0.14581 13.534 3.31e-11 *** ## poly(t, 4)2 0.54728 0.14581 3.753 0.00135 ** ## poly(t, 4)3 0.30678 0.14581 2.104 0.04892 * ## poly(t, 4)4 -0.14180 0.14581 -0.972 0.34302 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1458 on 19 degrees of freedom ## Multiple R-squared: 0.9143,\tAdjusted R-squared: 0.8962 ## F-statistic: 50.65 on 4 and 19 DF, p-value: 7.096e-10 2.1.2 Residual diagnostics We want to test if our residuals are temporally independent. We can do this with the Ljung-Box test as Stergio and Christou do. For the Ljung-Box test Null hypothesis is that the data are independent Alternate hypothesis is that the data are serially correlated Example of the Ljung-Box test Box.test(rnorm(100), type=&quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: rnorm(100) ## X-squared = 1.2273, df = 1, p-value = 0.2679 The null hypothesis is not rejected. These are not serially correlated. Stergio and Christou appear to use a lag of 14 for the test (this is a bit large for 24 data points). The degrees of freedom is lag minus the number of estimated parameters in the model. So for the Anchovy data, \\(df = 14 - 2\\). x &lt;- resid(model) Box.test(x, lag = 14, type = &quot;Ljung-Box&quot;, fitdf=2) ## ## Box-Ljung test ## ## data: x ## X-squared = 14.627, df = 12, p-value = 0.2625 Compare to the values in the far right column in Table 4. The null hypothesis of independence is rejected. Breusch-Godfrey test Although Stergiou and Christou use the Ljung-Box test, the Breusch-Godfrey test is more standard for regression residuals. The forecast package has the checkresiduals() function which will run this test and some diagnostic plots. forecast::checkresiduals(model) ## ## Breusch-Godfrey test for serial correlation of order up to 8 ## ## data: Residuals ## LM test = 12.858, df = 8, p-value = 0.1168 2.1.3 Compare to Stergiou and Christou Stergiou and Christou (1996) fit time-varying regressions to the 1964-1987 data and show the results in Table 4. Table 4 Compare anchovy fit to Stergiou and Christou Stergiou and Christou use a first order polynomial, linear relationship with time, for the anchovy data. They do not state how they choose this over a 2nd order polynomial which also appears supported (see fit with poly() fit to the anchovy data). anchovy87$t = anchovy87$Year-1963 model &lt;- lm(log.metric.tons ~ t, data=anchovy87) The coefficients and adjusted R2 are similar to that shown in their Table 4. The coefficients are not identical so there may be some differences in the data I extracted from the Greek statistical reports and those used in Stergiou and Christou. c(coef(model), summary(model)$adj.r.squared) ## (Intercept) t ## 8.36143085 0.05818942 0.81856644 Compare sardine fit to Stergiou and Christou For the sardine (bottom row in Table 4), Stergio and Christou fit a 4th order polynomial. With poly(), a 4th order time-varying regression model is fit to the sardine data as: sardine87$t = sardine87$Year-1963 model &lt;- lm(log.metric.tons ~ poly(t,4), data=sardine87) This indicates support for the 2nd, 3rd, and 4th orders but not the 1st (linear) part. summary(model) ## ## Call: ## lm(formula = log.metric.tons ~ poly(t, 4), data = sardine87) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.115300 -0.053090 -0.008895 0.041783 0.165885 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.31524 0.01717 542.470 &lt; 2e-16 *** ## poly(t, 4)1 0.08314 0.08412 0.988 0.335453 ## poly(t, 4)2 -0.18809 0.08412 -2.236 0.037559 * ## poly(t, 4)3 -0.35504 0.08412 -4.220 0.000463 *** ## poly(t, 4)4 0.25674 0.08412 3.052 0.006562 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.08412 on 19 degrees of freedom ## Multiple R-squared: 0.6353,\tAdjusted R-squared: 0.5586 ## F-statistic: 8.275 on 4 and 19 DF, p-value: 0.0004846 Stergiou and Christou appear to have used a raw polynomial model using \\(t\\), \\(t^2\\), \\(t^3\\) and \\(t^4\\) as the covariates instead of orthogonal polynomials. To fit the model that they did, we use model &lt;- lm(log.metric.tons ~ t + I(t^2) + I(t^3) + I(t^4), data=sardine87) Using a model fit with the raw time covariates, the coefficients and adjusted R2 are similar to that shown in Table 4. c(coef(model), summary(model)$adj.r.squared) ## (Intercept) t I(t^2) I(t^3) I(t^4) ## 9.672783e+00 -2.443273e-01 3.738773e-02 -1.983588e-03 3.405533e-05 ## ## 5.585532e-01 The test for autocorrelation of the residuals is x &lt;- resid(model) Box.test(x, lag = 14, type = &quot;Ljung-Box&quot;, fitdf=5) ## ## Box-Ljung test ## ## data: x ## X-squared = 32.317, df = 9, p-value = 0.0001755 fitdf specifies the number of parameters estimated by the model. In this case it is 5, intercept and 4 coefficients. The p-value is less than 0.05 indicating that the residuals are temporally correlated. 2.1.4 Summary Why use time-varying regression? It looks there is a simple time relationship. If a high-order polynomial is required, that is a bad sign. Easy and fast Easy to explain You are only forecasting a few years ahead No assumptions required about ‘stationarity’ Why not to use time-varying regression? Autocorrelation is not modeled. That autocorrelation may hold information for forecasting. You are only using temporal trend for forecasting (mean level). If you use a high-order polynomial, you might be modeling noise from a random walk. That means interpreting the temporal pattern as having information when in fact it has none. Is time-varying regression used? It seems pretty simple. Is this used? All the time. Most “trend” analyses are a variant of time-varying regression. If you fit a line to your data and report the trend or percent change, that’s a time-varying regression. "],
["2-2-forecasting.html", "2.2 Forecasting", " 2.2 Forecasting Forecasting is easy in R once you have a fitted model. Let’s say for the anchovy, we fit the model \\[C_t = \\alpha + \\beta t + e_t\\] where \\(t\\) starts at 1 (so 1964 is \\(t=1\\) ). To predict, predict the catch in year t, we use \\[C_t = \\alpha + \\beta t + e_t\\] Model fit: require(FishForecast) anchovy87$t &lt;- anchovy87$Year-1963 model &lt;- lm(log.metric.tons ~ t, data=anchovy87) coef(model) ## (Intercept) t ## 8.36143085 0.05818942 For anchovy, the estimated \\(\\alpha\\) (Intercept) is 8.3614309 and \\(\\beta\\) is 0.0581894. We want to use these estimates to forecast 1988 ( \\(t=25\\) ). So the 1988 forecast is 8.3614309 + 0.0581894 \\(\\times\\) 25 : coef(model)[1]+coef(model)[2]*25 ## (Intercept) ## 9.816166 log metric tons. 2.2.1 The forecast package The forecast package in R makes it easy to create forecasts with fitted models and to plot (some of) those forecasts. For a TV Regression model, our forecast() call looks like fr &lt;- forecast::forecast(model, newdata = data.frame(t=25:29)) The dark grey bands are the 80% prediction intervals and the light grey are the 95% prediction intervals. plot(fr) Anchovy forecasts from a higher order polynomial can similarly be made. Let’s fit a 4-th order polynomial. \\[C_t = \\alpha + \\beta_1 t + \\beta_2 t^2 + \\beta_3 t^3 + \\beta_4 t^4 + e_t\\] To forecast with this model, we fit the model to estimate the \\(\\beta\\)’s and then replace \\(t\\) with \\(24\\): \\[C_{1988} = \\alpha + \\beta_1 24 + \\beta_2 24^2 + \\beta_3 24^3 + \\beta_4 24^4 + e_t\\] This is how to do that in R: model &lt;- lm(log.metric.tons ~ t + I(t^2) + I(t^3) + I(t^4), data=anchovy87) fr &lt;- forecast::forecast(model, newdata = data.frame(t=24:28)) fr ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 1 10.05019 9.800941 10.29944 9.657275 10.44310 ## 2 10.18017 9.856576 10.50377 9.670058 10.69028 ## 3 10.30288 9.849849 10.75591 9.588723 11.01704 ## 4 10.41391 9.770926 11.05689 9.400315 11.42750 ## 5 10.50839 9.609866 11.40691 9.091963 11.92482 Unfortunately, forecast’s plot() function for forecast objects does not recognize that there is only one predictor \\(t\\) thus we cannot use forecast’s plot function. If you do this in R, it throws an error. try(plot(fr)) ## Error in plotlmforecast(x, PI = PI, shaded = shaded, shadecols = shadecols, : ## Forecast plot for regression models only available for a single predictor Error in plotlmforecast(x, PI = PI, shaded = shaded, shadecols = shadecols, : Forecast plot for regression models only available for a single predictor I created a function that you can use to plot time-varying regressions with polynomial \\(t\\). You will use this function in the lab. plotforecasttv(model, ylims=c(8,17)) A feature of a time-varying regression with many polynomials is that it fits the data well, but the forecast quickly becomes uncertain due to uncertainty regarding the polynomial fit. A simpler model can give forecasts that do not become rapidly uncertain. The flip-side is that the simpler model may not capture the short-term trends very well and may suffer from autocorrelated residuals. model &lt;- lm(log.metric.tons ~ t + I(t^2), data=anchovy87) plotforecasttv(model, ylims=c(8,17)) "],
["2-3-summary.html", "2.3 Summary", " 2.3 Summary Time-varying regression is a simple approach to forecasting that allows a non-linear trend. The uncertainty in your forecast is determined by how much error there is between the fit an the data. Fit must be balanced against prediction uncertainty. R allows you to quickly fit models and compute the prediction intervals. Careful thought must be given to selecting the polynomial order. Standard methods are available in R for order selection Using different orders for different data sets has prediction consequences "],
["3-arima-models.html", "Chapter 3 ARIMA Models", " Chapter 3 ARIMA Models The basic idea in an ARMA model is that past values in the time series have information about the current state. An AR model, the first part of ARMA, models the current state as a linear function of past values: \\[x_t = \\phi_1 x_{t-1} + \\phi_2 x_{t-2} + ... + \\phi_p x_{t-p} + e_t\\] "],
["3-1-overview.html", "3.1 Overview", " 3.1 Overview 3.1.1 Components of an ARIMA model You will commonly see ARIMA models referred to as Box-Jenkins models. This model has 3 components (p, d, q): AR autoregressive \\(y_t\\) depends on past values. The AR level is maximum lag \\(p\\). \\[x_t = \\phi_1 x_{t-1} + \\phi_2 x_{t-2} + ... + \\phi_p x_{t-p} + e_t\\] I differencing \\(x_t\\) may be a difference of the observed time series. The number of differences is denoted \\(d\\). First difference is \\(d=1\\): \\[x_t = y_t - y_{t-1}\\] MA moving average The error \\(e_t\\) can be a sum of a time series of independent random errors. The maximum lag is denoted \\(q\\). \\[e_t = \\eta_t + \\theta_1 \\eta_{t-1} + \\theta_2 \\eta_{t-2} + ... + \\theta_q \\eta_{t-q},\\quad \\eta_t \\sim N(0, \\sigma)\\] Create some data from an AR(2) Model \\[x_t = 0.5 x_{t-1} + 0.3 x_{t-2} + e_t\\] dat = arima.sim(n=1000, model=list(ar=c(.5,.3))) plot(dat) abline(h=0, col=&quot;red&quot;) Compare AR(2) and random data. AR(2) is auto-correlated Plot the data at time \\(t\\) against the data at time \\(t-1\\) 3.1.2 Box-Jenkins method This refers to a step-by-step process of selecting a forecasting model. You need to go through the steps otherwise you could end up fitting a nonsensical model or using fitting a sensible model with an algorithm that will not work on your data. A. Model form selection Evaluate stationarity and seasonality Selection of the differencing level (d) Selection of the AR level (p) Selection of the MA level (q) B. Parameter estimation C. Model checking 3.1.3 ACF and PACF functions The ACF function The auto-correlation function (ACF) is the correlation between the data at time \\(t\\) and \\(t+1\\). This is one of the basic diagnostic plots for time series data. acf(dat[1:50]) The ACF simply shows the correlation between all the data points that are lag \\(p\\) apart. Here are the correlations for points lag 1 and lag 10 apart. cor() is the correlation function. cor(dat[2:TT], dat[1:(TT-1)]) ## [1] 0.7022108 cor(dat[11:TT], dat[1:(TT-10)]) ## [1] 0.1095311 The values match what we see in the ACF plot. ACF for independent data Temporally independent data shows no significant autocorrelation. PACF function In the ACF for the AR(2), we see that \\(x_t\\) and \\(x_{t-3}\\) are correlated even those the model for \\(x_t\\) does not include \\(x_{t-3}\\). \\(x_{t-3}\\) is correlated with \\(x_t\\) indirectly because \\(x_{t-3}\\) is directly correlated with \\(x_{t-2}\\) and \\(x_{t-1}\\) and these two are in turn directly correlated with \\(x_t\\). The partial autocorrelation function removes this indirect correlation. Thus the only significant lags in the PACF should be the lags that appear in the process model. For example, if the model is Partial ACF for AR(2) \\[x_t = 0.5 x_{t-1} + 0.3 x_{t-2} + e_t\\] then only the first two lags should be significant in the PACF. pacf(dat) Partial ACF for AR(1) Similarly if the process model is \\[x_t = 0.5 x_{t-1} + e_t\\] The PACF should only have significant values at lag 1. dat &lt;- arima.sim(TT, model=list(ar=c(.5))) pacf(dat) "],
["3-2-stationarity.html", "3.2 Stationarity", " 3.2 Stationarity The first two steps of the Box-Jenkins Method have to do with evaluating for stationarity and correcting for lack of stationarity in your data: A. Model form selection Evaluate stationarity and seasonality Selection of the differencing level (d) Selection of the AR level (p) Selection of the MA level (q) B. Parameter estimation C. Model checking 3.2.1 Definition Stationarity means ‘not changing in time’ in the context of time-series models. Typically we test the trend and variance, however more generally all statistical properties of a time-series is time-constant if the time series is ‘stationary’. Many ARMA models exhibit stationarity. White noise is one type: \\[x_t = e_t, e_t \\sim N(0,\\sigma)\\] ## Loading required package: gridExtra ## Loading required package: reshape2 An AR-1 process with \\(b&lt;1\\) \\[x_t = b x_{t-1} + e_t\\] is also stationary. Stationarity around a trend The processes shown above have mean 0 and a flat level. We can also have stationarity around an non-zero level or stationarity around an linear trend. If \\(b=0\\), we have white noise and if \\(b&lt;1\\) we have AR-1. Non-zero mean: \\(x_t = \\mu + b x_{t-1} + e_t\\) Linear trend: \\(x_t = \\mu + at + b x_{t-1} + e_t\\) 3.2.2 Non-stationarity One of the most common forms of non-stationarity that is tested for is ‘unit root’, which means that the process is a random walk: \\[x_t = x_{t-1} + e_t\\] . Non-stationarity with a trend Similar to the way we added an intecept and linear trend to the stationarity processes, we can do the same to the random walk. Non-zero mean or intercept: \\(x_t = \\mu + x_{t-1} + e_t\\) Linear trend: \\(x_t = \\mu + at + x_{t-1} + e_t\\) The effects are fundamentally different however. The addition of \\(\\mu\\) leads to a upward mean linear trend while the addition of \\(at\\) leads to exponential growth. 3.2.3 Stationarity tests Why is evaluating stationarity important? Many AR models have a flat level or trend and time-constant variance. If your data do not have those properties, you are fitting a model that is fundamentally inconsistent with your data. Many standard algorithms for fitting ARIMA models assume stationarity. Note, you can fit ARIMA models without making this assumption, but you need to use the appropriate algorithm. We will discuss three common approaches to evaluating stationarity: Visual test (Augmented) Dickey-Fuller test KPSS test Visual test The visual test is simply looking at a plot of the data versus time. Look for Change in the level over time. Is the time series increasing or decreasing? Does it appear to cycle? Change in the variance over time. Do deviations away from the mean change over time, increase or decrease? Here is a plot of the anchovy and sardine in Greek waters from 1965 to 1989. The anchovies have an obvious non-stationary trend during this period. The mean level is going up. The sardines have a roughly stationary trend. The variance (deviations away from the mean) appear to be roughly stationary, neither increasing or decreasing in time. Although the logged anchovy time series is increasing, it appears to have an linear trend. Dickey-Fuller test The Dickey=Fuller test (and Augmented Dickey-Fuller test) look for evidence that the time series has a unit root. The null hypothesis is that the time series has a unit root, that is, it has a random walk component. The alternative hypothesis is some variation of stationarity. The test has three main verisons. Visually, the null and alternative hypotheses for the three Dickey-Fuller tests are the following. It is hard to see but in the panels on the left, the variance around the trend is increasing and on the right, it is not. Mathematically, here are the null and alternative hypotheses. In each, we are testing if \\(\\delta=0\\). Null is a random walk with no drift \\(x_t = x_{t-1}+e_t\\) Alternative is a mean-reverting (stationary) process with zero mean. \\(x_t = \\delta x_{t-1}+e_t\\) Null is a random walk with drift (linear STOCHASTIC trend) \\(x_t = \\mu + x_{t-1} + e_t\\) Alternative is a mean-reverting (stationary) process with non-zero mean and no trend. \\(x_t = \\mu + \\delta x_{t-1} + e_t\\) Null is a random walk with exponential trend \\(x_t = \\mu + at + x_{t-1} + e_t\\) Alternative is a mean-reverting (stationary) process with non-zero mean and linear DETERMINISTIC trend. \\(x_t = \\mu + at + \\delta x_{t-1} + e_t\\) Example: Dickey-Fuller test using adf.test() adf.test() in the tseries package will apply the Augemented Dickey-Fuller and report the p-value. We want to reject the Dickey=Fuller null hypothesis of non-stationarity. We will set k=0 to apply the Dickey-Fuller test which tests for AR(1) stationarity. The Augmented Dickey-Fuller tests for more general lag-p stationarity. adf.test(x, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;), k = trunc((length(x)-1)^(1/3))) x is the time-series data in vector or ts form. Here is how to apply this test to the anchovy data tseries::adf.test(anchovy87ts, k=0) ## ## Augmented Dickey-Fuller Test ## ## data: anchovy87ts ## Dickey-Fuller = -2.8685, Lag order = 0, p-value = 0.2415 ## alternative hypothesis: stationary # or tseries::adf.test(anchovy87$log.metric.tons, k=0) The null hypothesis is not rejected. That is not what we want. Example: Dickey-Fuller test using ur.df() The urca R package can also be used to apply the Dickey-Fuller tests. Use lags=0 for Dickey-Fuller which tests for AR(1) stationarity. We will set type=\"trend\" to deal with the trend seen in the anchovy data. Note, adf.test() uses this type by default. ur.df(y, type = c(&quot;none&quot;, &quot;drift&quot;, &quot;trend&quot;), lags = 0) test = urca::ur.df(anchovy87ts, type=&quot;trend&quot;, lags=0) test ## ## ############################################################### ## # Augmented Dickey-Fuller Test Unit Root / Cointegration Test # ## ############################################################### ## ## The value of the test statistic is: -2.8685 4.0886 4.7107 ur.df() will report the test statistic. You can look up the values of the test statistic for different \\(\\alpha\\) levels using summary(test) or attr(test, \"cval\"). If the test statistic is less than the critical value for \\(\\alpha\\)=0.05 (‘5pct’ in cval), it means the null hypothesis of non-stationarity is rejected. For the Dickey-Fuller test, you do want to reject the null hypothesis. The test statistic is attr(test, &quot;teststat&quot;) ## tau3 phi2 phi3 ## statistic -2.86847 4.088559 4.71069 and the critical value at \\(\\alpha = 0.05\\) is attr(test,&quot;cval&quot;) ## 1pct 5pct 10pct ## tau3 -4.38 -3.60 -3.24 ## phi2 8.21 5.68 4.67 ## phi3 10.61 7.24 5.91 The statistic is larger than the critical value and thus the null hypothesis of non-stationarity is not rejected. That’s not what we want. Augmented Dickey-Fuller test The Dickey-Fuller test assumes that the stationary process is AR(1) (autoregressive lag-1). The Augmented Dickey-Fuller test allows a general stationary process. The idea of the test however is the same. We can apply the Augmented Dickey-Fuller test with the ur.df() function or the adf.test() function in the tseries package. adf.test(x, alternative = c(&quot;stationary&quot;, &quot;explosive&quot;), k = trunc((length(x)-1)^(1/3))) The alternative is either stationary like \\(x_t = \\delta x_{t-1} + \\eta_t\\) with \\(\\delta&lt;1\\) or ‘explosive’ with \\(\\delta&gt;1\\). k is the number of lags which determines the number of time lags allowed in the autoregression. k is generally determined by the length of your time series. Example: Augmented Dickey-Fuller tests with adf.test() With the tseries package, we apply the Augmented Dickey-Fuller test with adf.test(). This function uses the test where the alternative model is stationary around a linear trend: \\(x_t = \\mu + at + \\delta x_{t-1} + e_t\\). tseries::adf.test(anchovy87ts) ## ## Augmented Dickey-Fuller Test ## ## data: anchovy87ts ## Dickey-Fuller = -0.57814, Lag order = 2, p-value = 0.9685 ## alternative hypothesis: stationary In both cases, we do not reject the null hypothesis that the data have a random walk. Thus there is not support for these time series being stationary. Example: Augmented Dickey-Fuller tests with ur.df() With the urca package, we apply the Augmented Dickey-Fuller test with ur.df(). The defaults for ur.df() are different than for adf.test(). ur.df() allows you to specify which of the 3 alternative hypotheses you want: none (stationary around 0), drift (stationary around a non-zero intercept), trend (stationary around a linear trend). Another difference is that by default, ur.df() uses a fixed lag of 1 while by default adf.test() selects the lag based on the length of the time series. We will specify “trend” to make the test similar to adf.test(). We will set the lags like adf.test() does also. k = trunc((length(anchovy87ts)-1)^(1/3)) test = urca::ur.df(anchovy87ts, type=&quot;trend&quot;, lags=k) test ## ## ############################################################### ## # Augmented Dickey-Fuller Test Unit Root / Cointegration Test # ## ############################################################### ## ## The value of the test statistic is: -0.5781 3.2816 0.8113 The test statistic values are the same, but we need to look up the critical values with summary(test). KPSS test In the Dickey-Fuller test, the null hypothesis is the unit root, i.e. random walk. Often times, there is not enough power to reject the null hypothesis. A null hypothesis is accepted unless there is strong evidence against it. The Kwiatkowski–Phillips–Schmidt–Shin (KPSS) test has as the null hypothesis that a time series is stationary around a level trend (or a linear trend). The alternative hypothesis for the KPSS test is a random walk. The stationarity assumption is general; it does not assume a specific type of stationarity such as white noise. If both KPSS and Dickey-Fuller tests support non-stationarity, then the stationarity assumption is not supported. Example: KPSS tests tseries::kpss.test(anchovy87ts, null=&quot;Trend&quot;) ## ## KPSS Test for Trend Stationarity ## ## data: anchovy87ts ## KPSS Trend = 0.19182, Truncation lag parameter = 2, p-value = 0.01907 Here null=\"Trend\" was included to account for the increasing trend in the data. The null hypothesis of stationarity is rejected. Thus both the KPSS and Dickey-Fuller tests support the hypothesis that the anchovy time series is non-stationary. That’s not what we want. 3.2.4 Differencing the data Differencing the data is used to correct non-stationarity. Differencing means to create a new time series \\(z_t = x_t - x_{t-1}\\). First order differencing means you do this once (so \\(z_t\\)) and second order differencing means you do this twice (so \\(z_t - z_{t-1}\\)). The diff() function takes the first difference: x &lt;- diff(c(1,2,4,7,11)) x ## [1] 1 2 3 4 The second difference is the first difference of the first difference. diff(x) ## [1] 1 1 1 Here is a plot of the anchovy data and its first difference. par(mfrow=c(1,2)) plot(anchovy87ts, type=&quot;l&quot;) title(&quot;Anchovy&quot;) plot(diff(anchovy87ts), type=&quot;l&quot;) title(&quot;Anchovy first difference&quot;) Let’s test the anchovy data with one difference using the KPSS test. diff.anchovy = diff(anchovy87ts) tseries::kpss.test(diff.anchovy) ## Warning in tseries::kpss.test(diff.anchovy): p-value greater than printed p- ## value ## ## KPSS Test for Level Stationarity ## ## data: diff.anchovy ## KPSS Level = 0.28972, Truncation lag parameter = 2, p-value = 0.1 The null hypothesis of stationairity is not rejected. That is good. Let’s test the first difference of the anchovy data using the Augmented Dickey-Fuller test. We do the default test and allow it to chose the number of lags. tseries::adf.test(diff.anchovy) ## ## Augmented Dickey-Fuller Test ## ## data: diff.anchovy ## Dickey-Fuller = -4.2126, Lag order = 2, p-value = 0.01584 ## alternative hypothesis: stationary The null hypothesis of non-stationarity is rejected. That is what we want. However, we differenced which removed the trend thus we are testing against a more general model than we need. Let’s test with an alternative hypothesis that has a non-zero mean but not trend. We can do this with ur.df() and type='drift'. test &lt;- urca::ur.df(diff.anchovy, type=&quot;drift&quot;, lags=2) The null hypothesis of NON-stationairity IS rejected. That is good. The test statistic is attr(test, &quot;teststat&quot;) ## tau2 phi1 ## statistic -3.492685 6.099778 and the critical value at \\(\\alpha = 0.05\\) is attr(test,&quot;cval&quot;) ## 1pct 5pct 10pct ## tau2 -3.75 -3.00 -2.63 ## phi1 7.88 5.18 4.12 3.2.5 Summary Test stationarity before you fit a ARMA model. Visual test: is the time series flutuating about a level or a linear trend? Yes or maybe? Apply a “unit root” test. (Augmented) Dickey-Fuller test KPSS test No or fails the unit root test. Apply differencing again and re-test. Still not passing? Try a second difference. Still not passing? ARMA model might not be the best choice. Or you may need to an adhoc detrend. "],
["3-3-model-structure.html", "3.3 Model structure", " 3.3 Model structure We are now at step A3 and A4 of the Box-Jenkins Method. Note we did not address seasonality since we are working with yearly data. A. Model form selection Evaluate stationarity and seasonality Selection of the differencing level (d) Selection of the AR level (p) Selection of the MA level (q) B. Parameter estimation C. Model checking Much of this will be automated when we use the forecast package 3.3.1 AR and MA lags Step A3 is to determine the number of \\(p\\) lags in the AR part of the model: \\[x_t = \\phi_1 x_{t-1} + \\phi_2 x_{t-2} + ... + \\phi_p x_{t-p} + e_t\\] Step A4 is to determine the number of \\(q\\) lags in the MA part of the model: \\[e_t = \\eta_t + \\theta_1 \\eta_{t-1} + \\theta_2 \\eta_{t-2} + ... + \\theta_q \\eta_{t-q},\\quad \\eta_t \\sim N(0, \\sigma)\\] 3.3.2 Model order For an ARIMA model, the number of AR lags, number of differences, and number of MA lags is called the model order or just order. Examples. Note \\(e_t \\sim N(0,\\sigma)\\) order (0,0,0) white noise \\[x_t = e_t\\] order (1,0,0) AR-1 process \\[x_t = \\phi x_{t-1} + e_t\\] order (0,0,1) MA-1 process \\[x_t = e_t + \\theta e_{t-1}\\] order (1,0,1) AR-1 MA-1 process \\[x_t = \\phi x_{t-1} + e_t + \\theta e_{t-1}\\] order (0,1,0) random walk \\[x_t - x_{t-1} = e_t\\] which is the same as \\[x_t = x_{t-1} + e_t\\] 3.3.3 Choosing the AR and MA levels Method #1 use the ACF and PACF functions The ACF plot shows you how the correlation between \\(x_t\\) and \\(x_{t+p}\\) decrease as \\(p\\) increases. The PACF plot shows you the same but removes the autocorrelation due to lags less that \\(p\\). If your ACF and PACF look like the top panel, it is AR-p. The first lag where the PACF is below the dashed lines is the \\(p\\) lag for your model. If it looks like the middle panel, it is MA-p. The first lag where the ACF is below the dashed lines is the \\(q\\) lag for your model. If it looks like the bottom panel, it is ARMA and this approach doesn’t work. Method #2 Use formal model selection This weighs how well the model fits against how many parameters your model has. We will use this approach. The auto.arima() function in the forecast package in R allows you to easily estimate the \\(p\\) and \\(q\\) for your ARMA model. We will use the first difference of the anchovy data since our stationarity diagnostics indicated that a first difference makes our time series stationary. anchovy.diff1 = diff(anchovy87$log.metric.tons) forecast::auto.arima(anchovy.diff1) ## Series: anchovy.diff1 ## ARIMA(0,0,1) with non-zero mean ## ## Coefficients: ## ma1 mean ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 The output indicates that the ‘best’ model is a MA-1 with a non-zero mean. “non-zero mean” means that the mean of our data (anchovy.diff1) is not zero. auto.arima() will also estimate the amount of differencing needed. forecast::auto.arima(anchovy87ts) ## Series: anchovy87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 The output indicates that the ‘best’ model is a MA-1 with first difference. “with drift” means that the mean of our data (anchovy87) is not zero. This is the same model but the jargon regarding the mean is different. More examples Let’s try fitting to some simulated data. We will simulate with arima.sim(). We will specify no differencing. set.seed(100) a1 = arima.sim(n=100, model=list(ar=c(.8,.1))) forecast::auto.arima(a1, seasonal=FALSE, max.d=0) ## Series: a1 ## ARIMA(1,0,0) with non-zero mean ## ## Coefficients: ## ar1 mean ## 0.6928 -0.5343 ## s.e. 0.0732 0.2774 ## ## sigma^2 estimated as 0.7703: log likelihood=-128.16 ## AIC=262.33 AICc=262.58 BIC=270.14 The ‘best-fit’ model is simpler than the model used to simulate the data. How often is the ‘true’ model is chosen? Let’s fit 100 simulated time series and see how often the ‘true’ model is chosen. By far the correct type of model is selected, AR-p, but usually a simpler model of AR-1 is chosen over AR-2 (correct) most of the time. save.fits = rep(NA,100) for(i in 1:100){ a1 = arima.sim(n=100, model=list(ar=c(.8,.1))) fit = forecast::auto.arima(a1, seasonal=FALSE, max.d=0, max.q=0) save.fits[i] = paste0(fit$arma[1], &quot;-&quot;, fit$arma[2]) } table(save.fits) ## save.fits ## 1-0 2-0 3-0 4-0 ## 74 20 5 1 3.3.4 Trace = TRUE You can see what models that auto.arima() tried using trace=TRUE. The models are selected on AICc by default and the AICc value is shown next to the model. forecast::auto.arima(anchovy87ts, trace=TRUE) ## ## ARIMA(2,1,2) with drift : 0.9971438 ## ARIMA(0,1,0) with drift : -1.582738 ## ARIMA(1,1,0) with drift : -3.215851 ## ARIMA(0,1,1) with drift : -5.727702 ## ARIMA(0,1,0) : -1.869767 ## ARIMA(1,1,1) with drift : -2.907571 ## ARIMA(0,1,2) with drift : -3.219136 ## ARIMA(1,1,2) with drift : -1.363802 ## ARIMA(0,1,1) : -1.425496 ## ## Best model: ARIMA(0,1,1) with drift ## Series: anchovy87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 3.3.5 stepwise = FALSE By default, step-wise selection is used and an approximation is used for the models tried in the model selection step. For a final model selection, you should turn these off. forecast::auto.arima(anchovy87ts, stepwise=FALSE, approximation=FALSE) ## Series: anchovy87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 3.3.6 Summary Once you have dealt with stationarity, you need to determine the order of the model: the AR part and the MA part. Although you could simply use auto.arima(), it is best to run acf() and pacf() on your data to understand it better. Does it look like a pure AR process? Also evaluate if there are reasons to assume a particular structure. Are you using an established model form, from say another paper? Are you fitting to a process that is fundamentally AR only or AR + MA? "],
["3-4-fitting-arima-models.html", "3.4 Fitting ARIMA models", " 3.4 Fitting ARIMA models We are now at step B of the Box-Jenkins Method. A. Model form selection Evaluate stationarity and seasonality Selection of the differencing level (d) Selection of the AR level (p) Selection of the MA level (q) B. Parameter estimation C. Model checking 3.4.1 Fitting with auto.arima() auto.arima() (in the forecast package) has many arguments. auto.arima(y, d = NA, D = NA, max.p = 5, max.q = 5, max.P = 2, max.Q = 2, max.order = 5, max.d = 2, max.D = 1, start.p = 2, start.q = 2, start.P = 1, start.Q = 1, stationary = FALSE, seasonal = TRUE, ic = c(&quot;aicc&quot;, &quot;aic&quot;, &quot;bic&quot;), stepwise = TRUE, trace = FALSE, approximation = (length(x) &gt; 150 | frequency(x) &gt; 12), truncate = NULL, xreg = NULL, test = c(&quot;kpss&quot;, &quot;adf&quot;, &quot;pp&quot;), seasonal.test = c(&quot;seas&quot;, &quot;ocsb&quot;, &quot;hegy&quot;, &quot;ch&quot;), allowdrift = TRUE, allowmean = TRUE, lambda = NULL, biasadj = FALSE, parallel = FALSE, num.cores = 2, x = y, ...) When just getting started, we will focus just on a few of these. trace To print out the models that were tested. stepwise and approximation To use slower but better estimation when selecting model order. test The test to use to select the amount of differencing. Load the data Load the data by loading the FishForecast package. require(FishForecast) anchovy87ts is a ts object of the log metric tons for 1964-1987. We will use this for auto.arima() however we could also use anchovy87$log.metric.tons. anchovy87ts is just anchovy87ts &lt;- ts(anchovy87, start=1964) Fit to the anchovy data using auto.arima() fit &lt;- forecast::auto.arima(anchovy87ts) Here are the values for anchovy in Table 8 of Stergiou and Christou. Model \\(\\theta_1\\) drift (c) R\\(^2\\) BIC LB (0,1,1) 0.563 0.064 0.83 1775 5.4 Here is the equivalent values from the best fit from auto.arima(): Model theta1 drift R2 BIC LB (0,1,1) 0.5731337 0.0640889 0.8402976 -3.584377 5.372543 Where do we find each of the components of Stergiou and Christou’s Table 8? The parameter estimates We can extract the parameter estimates from a fitted object in R using coef(). coef(fit) ## ma1 drift ## -0.5731337 0.0640889 The ma1 is the same as \\(\\theta_1\\) except its negative because of the way Stergiou and Christou write their MA models. They write it as \\[e_t = \\eta_t - \\theta_1 \\eta_{t-1}\\] instead of the form that auto.arima() uses \\[e_t = \\eta_t + \\theta_1 \\eta_{t-1}\\] Computing R2 This is not output as part of a arima fitted object so we need to compute it. res &lt;- resid(fit) dat &lt;- anchovy87$log.metric.tons meany &lt;- mean(dat, na.rm=TRUE) r2 &lt;- 1- sum(res^2,na.rm=TRUE)/sum((dat-meany)^2,na.rm=TRUE) Ljung-Box statistic LB &lt;- Box.test(res, type=&quot;Ljung-Box&quot;, lag=12, fitdf=2)$statistic fitdf=2 is from the number of parameters estimated. BIC BIC is in fit$BIC. Why is BIC different? Because there is a missing constant, which is fairly common. The absolute value of BIC is unimportant. Only its value relative to other models that you tested is important. 3.4.2 Outputting the models tested Pass in trace=TRUE to see a list of the models tested in auto.arima()’s search. By default auto.arima() uses AICc for model selection and the AICc values are shown. Smaller is better for AICc and AICc values that are different by less than 2 have similar data support. Look for any models with similar AICc to the best selected model. You should consider that model also. forecast::auto.arima(anchovy87ts, trace=TRUE) ## ## ARIMA(2,1,2) with drift : 0.9971438 ## ARIMA(0,1,0) with drift : -1.582738 ## ARIMA(1,1,0) with drift : -3.215851 ## ARIMA(0,1,1) with drift : -5.727702 ## ARIMA(0,1,0) : -1.869767 ## ARIMA(1,1,1) with drift : -2.907571 ## ARIMA(0,1,2) with drift : -3.219136 ## ARIMA(1,1,2) with drift : -1.363802 ## ARIMA(0,1,1) : -1.425496 ## ## Best model: ARIMA(0,1,1) with drift ## Series: anchovy87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 3.4.3 Repeat with the sardine data Stergiou and Christou sardine model (Table 8) is ARIMA(0,1,0): \\[x_t = x_{t-1}+e_t\\] The model selected by auto.arima() is ARIMA(0,0,1): \\[x_t = e_t + \\theta_1 e_{t-1}\\] forecast::auto.arima(sardine87ts) ## Series: sardine87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 Why? Stergiou and Christou used the Augmented Dickey-Fuller test to determine the amount of differencing needed while the default for auto.arima() is to use the KPSS test. Repeat using test='adf' Now the selected model is the same. fit &lt;- auto.arima(sardine87ts, test=&quot;adf&quot;) fit ## Series: sardine87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 Compare the estimated values in Stergiou and Christou Table 8: Model \\(\\theta_1\\) drift (c) R2 BIC LB (0,1,0) NA NA 0.00 1396 22.2 versus from auto.arima() ## Warning in mean.default(sardine, na.rm = TRUE): argument is not numeric or ## logical: returning NA ## Warning in Ops.factor(left, right): &#39;-&#39; not meaningful for factors Model theta1 drift R2 BIC LB (0,1,0) 0.5731337 0.0640889 -Inf -3.584377 5.372543 3.4.4 Missing values These functions work fine with missing values. Missing values are denoted NA. anchovy.miss &lt;- anchovy87ts anchovy.miss[10:14] &lt;- NA fit &lt;- auto.arima(anchovy.miss) fit ## Series: anchovy.miss ## ARIMA(1,1,0) with drift ## ## Coefficients: ## ar1 drift ## -0.5622 0.067 ## s.e. 0.2109 0.022 ## ## sigma^2 estimated as 0.02947: log likelihood=6.35 ## AIC=-6.71 AICc=-5.45 BIC=-3.3 3.4.5 Fit a specific ARIMA model Sometimes you don’t want to search, but rather fit an ARIMA model with a specific order. Say you wanted to fit this model: \\[x_t = \\beta_1 x_{t-1} + \\beta_2 x_{t-2} + e_t\\] For that you can use Arima() in the forecast package: fit.AR2 &lt;- forecast::Arima(anchovy87ts, order=c(2,0,0)) fit.AR2 ## Series: anchovy87ts ## ARIMA(2,0,0) with non-zero mean ## ## Coefficients: ## ar1 ar2 mean ## 0.6912 0.2637 9.2353 ## s.e. 0.2063 0.2142 0.5342 ## ## sigma^2 estimated as 0.0511: log likelihood=2.1 ## AIC=3.81 AICc=5.91 BIC=8.52 3.4.6 Model checking Plot your data Is the plot long-tailed (Chl, some types of fish data)? Take the logarithm. Fit model. Plot your residuals Check your residuals for stationarity, normality, and independence Ideally your response variable will be unimodal. If not, you are using an ARIMA model that doesn’t produce data like yours. While you could change the assumptions about the error distribution in the model, it will be easier to transform your data. Look at histograms of your data: Use checkresiduals() to do basic diagnostics. fit &lt;- forecast::auto.arima(anchovy87ts) checkresiduals(fit) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(0,1,1) with drift ## Q* = 1.4883, df = 3, p-value = 0.685 ## ## Model df: 2. Total lags used: 5 3.4.7 Workflow for non-seasonal data Go through Box-Jenkins Method to evaluate stationarity Plot the data and make decisions about transformations to make the data more unimodal Make some decisions about differencing and any other data transformations via the stationarity tests Use auto.arima(data, trace=TRUE) to evaluate what ARMA models best fit the data. Fix the differencing if needed. Determine a set of candidate models. Include a null model in the candidate list. naive and naive with drift are typical nulls. Test candidate models for forecast performance with cross-validation (next lecture). 3.4.8 Stepwise vs exhaustive model selection Stepwise model selection is fast and useful if you need to explore many models and it takes awhile to fit each model. Our models fit quickly and we don’t have season in our models. Though it will not make a difference for this particular dataset, in general set stepwise=FALSE to do a more thorough model search. forecast::auto.arima(anchovy87ts, stepwise=FALSE, approximation=FALSE) ## Series: anchovy87ts ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.5731 0.0641 ## s.e. 0.1610 0.0173 ## ## sigma^2 estimated as 0.03583: log likelihood=6.5 ## AIC=-6.99 AICc=-5.73 BIC=-3.58 3.4.9 Summary auto.arima() in the forecast package is a good choice for selection and fitting of ARIMA models. Arima() is a good choice when you know the order (structure) of the model. You (may) need to know whether the mean of the data should be zero and whether it is stationary around a linear line. include.mean=TRUE means the mean is not zero include.drift=TRUE means fit a model that fluctuates around a trend (up or down) "],
["3-5-forecasting.html", "3.5 Forecasting", " 3.5 Forecasting The basic idea of forecasting with an ARIMA model is the same as forecasting with a time-varying regressiion model. We estimate a model and the parameters for that model. For example, let’s say we want to forecast with ARIMA(2,1,0) model: \\[y_t = \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + e_t\\] where \\(y_t\\) is the first difference of our anchovy data. Let’s estimate the \\(\\beta\\)’s for this model from the 1964-1987 anchovy data. fit &lt;- Arima(anchovy87ts, order=c(2,1,0)) coef(fit) ## ar1 ar2 ## -0.3347994 -0.1453928 So we will forecast with this model: \\[y_t = -0.3348 y_{t-1} - 0.1454 y_{t-2} + e_t\\] So to get our forecast for 1988, we do this \\[(y_{1988}-y_{1987}) = -0.3348 (y_{1987}-y_{1986}) - 0.1454 (y_{1986}-y_{1985})\\] Thus \\[y_{1988} = y_{1987}-0.3348 (y_{1987}-y_{1986}) - 0.1454 (y_{1986}-y_{1985})\\] Here is R code to do that: anchovy87ts[24]+coef(fit)[1]*(anchovy87ts[24]-anchovy87ts[23])+ coef(fit)[2]*(anchovy87ts[23]-anchovy87ts[22]) ## ar1 ## 10.00938 3.5.1 Forecasting with forecast() forecast(fit, h=h) automates the forecast calculations for us. forecast() takes a fitted object, fit, from arima() and output forecasts for h time steps forward. The upper and lower prediction intervals are also computed. fit &lt;- forecast::auto.arima(sardine87ts, test=&quot;adf&quot;) fr &lt;- forecast::forecast(fit, h=5) fr ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 1988 10.03216 9.789577 10.27475 9.661160 10.40317 ## 1989 10.09625 9.832489 10.36001 9.692861 10.49964 ## 1990 10.16034 9.876979 10.44370 9.726977 10.59371 ## 1991 10.22443 9.922740 10.52612 9.763035 10.68582 ## 1992 10.28852 9.969552 10.60749 9.800701 10.77634 We can plot our forecast with prediction intervals. Here is the sardine forecast: plot(fr, xlab=&quot;Year&quot;) Forecast for anchovy fit &lt;- forecast::auto.arima(anchovy87ts) fr &lt;- forecast::forecast(fit, h=5) plot(fr) Forecasts for chub mackerel We can repeat for other species. spp=&quot;Chub.mackerel&quot; dat &lt;- subset(greeklandings, Species==spp &amp; Year&lt;=1987)$log.metric.tons dat &lt;- ts(dat, start=1964) fit &lt;- forecast::auto.arima(dat) fr &lt;- forecast::forecast(fit, h=5) plot(fr, ylim=c(6,10)) 3.5.2 Missing values Missing values are allowed for arima() and we can product forecasts with the same code. anchovy.miss &lt;- anchovy87ts anchovy.miss[10:14] &lt;- NA fit &lt;- forecast::auto.arima(anchovy.miss) fr &lt;- forecast::forecast(fit, h=5) plot(fr) 3.5.3 Null forecast models Whenever we are testing a forecast model or procedure we have developed, we should test against ‘null’ forecast models. These are standard ‘competing’ forecast models. The Naive forecast The Naive forecast with drift The mean or average forecast The “Naive” forecast The “naive” forecast is simply the last value observed. If we want to prediction landings in 2019, the naive forecast would be the landings in 2018. This is a difficult forecast to beat! It has the advantage of having no parameters. In forecast, we can fit this model with the naive() function. Note this is the same as the rwf() function. fit.naive &lt;- forecast::naive(anchovy87ts) fr.naive &lt;- forecast::forecast(fit.naive, h=5) plot(fr.naive) The “Naive” forecast with drift The “naive” forecast is equivalent to a random walk with no drift. So this \\[x_t = x_{t-1} + e_t\\] As you saw with the anchovy fit, it doesn’t allow an upward trend. Let’s make it a little more flexible by add drift. This means we estimate one term, the trend. \\[x_t = \\mu + x_{t-1} + e_t\\] fit.rwf &lt;- forecast::rwf(anchovy87ts, drift=TRUE) fr.rwf &lt;- forecast::forecast(fit.rwf, h=5) plot(fr.rwf) The “mean” forecast The “mean” forecast is simply the mean of the data. If we want to prediction landings in 2019, the mean forecast would be the average of all our data. This is a poor forecast typically. It uses no information about the most recent values. In forecast, we can fit this model with the Arima() function and order=c(0,0,0). This will fit this model: \\[x_t = e_t\\] where \\(e_t \\sim N(\\mu, \\sigma)\\). fit.mean &lt;- forecast::Arima(anchovy87ts, order=c(0,0,0)) fr.mean &lt;- forecast::forecast(fit.mean, h=5) plot(fr.mean) "],
["4-exponential-smoothing-models.html", "Chapter 4 Exponential smoothing models", " Chapter 4 Exponential smoothing models The basic idea with an exponential smoothing model is that your forecast of \\(x\\) at time \\(t\\) is a smoothed function of past \\(x\\) values. \\[\\hat{x}_{t} = \\alpha x_{t-1} + \\alpha (1-\\alpha)^2 x_{t-2} + \\alpha (1-\\alpha)^3 x_{t-3} + \\dots\\] Although this looks similar to an AR model with a constraint on the \\(\\beta\\) terms, it is fundamentally different. There is no process model and one is not assuming that \\[x_{t} = \\alpha x_{t-1} + \\alpha (1-\\alpha)^2 x_{t-2} + \\alpha (1-\\alpha)^3 x_{t-3} + \\dots + e_t\\] The goal is to find the \\(\\alpha\\) that minimizes \\(x_t - \\hat{x}_t\\), i.e. the forecast error. The issues regarding stationarity do not arise because we are not fitting a stationary process model. We are not fitting a process model at all.\n"],
["4-1-overview.html", "4.1 Overview", " 4.1 Overview 4.1.1 Naive model Let’s start with a simple example, an exponential smoothing model with \\(\\alpha=1\\). This is called the Naive model: \\[\\hat{x}_{t} = x_{t-1}\\] For the naive model, our forecast is simply the value in the previous time step. For example, a naive forecast of the anchovy landings in 1988 is the anchovy landings in 1987. \\[\\hat{x}_{1988} = x_{1987}\\] This is the same as saying that we put 100% of the ‘weight’ on the most recent value and no weight on any value prior to that. \\[\\hat{x}_{1988} = 1 \\times x_{1987} + 0 \\times x_{1986} + 0 \\times x_{1985} + \\dots\\] Past values in the time series have information about the current state, but only the most recent past value. We can fit this with forecast::Arima(). fit.rwf &lt;- forecast::Arima(anchovy87ts, order=c(0,1,0)) fr.rwf &lt;- forecast::forecast(fit.rwf, h=5) Alternatively we can fit with rwf() or naive() which are shortcuts for the above lines. All fit the same model. fr.rwf &lt;- forecast::rwf(anchovy87ts, h=5) fr.rwf &lt;- forecast::naive(anchovy87ts, h=5) A plot of the forecast shows the forecast and the prediction intervals. plot(fr.rwf) 4.1.2 Exponential smoothing The naive model is a bit extreme. Often the values prior to the last value also have some information about future states. But the ‘information content’ should decrease the farther in the past that we go. A smoother is another word for a filter, which in time series parlance means a weighted sum of sequential values in a time series: \\[w_1 x_t + w_2 x_{t-1} + w_3 x_{t-2} + \\dots\\] An exponential smoother is a filter (weighted sum) where the weights decline exponentially (Figure @ref(fig:ets.alpha)). (#fig:ets.alpha)Weighting function for exponential smoothing filter. The shape is determined by \\(lpha\\). 4.1.3 Exponential smoothing model A simple exponential smoothing model is like the naive model that just uses the last value to make the forecast, but instead of only using the last value it will use values farther in the past also. The weighting function falls off exponentially as shown above. Our goal when fitting an exponential smoothing model is to find the the \\(\\alpha\\), which determines the shape of the weighting function (Figure @ref(fig:ets.alpha2)), that minimizes the forecast errors. (#fig:ets.alpha2)The size of \\(lpha\\) determines how past values affect the forecast. "],
["4-2-ets-function.html", "4.2 ets() function", " 4.2 ets() function The ets() function in the forecast package fits exponential smoothing models and produces forecasts from the fitted models. It also includes functions for plotting forecasts. Load the data by loading the FishForecast package. require(FishForecast) Fit the model. fit &lt;- forecast::ets(anchovy87ts, model=&quot;ANN&quot;) model=\"ANN\" specifies the simple exponential smoothing model. Create a forecast for 5 time steps into the future. fr &lt;- forecast::forecast(fit, h=5) Plot the forecast. plot(fr) Look at the estimates fit ## ETS(A,N,N) ## ## Call: ## forecast::ets(y = anchovy87ts, model = &quot;ANN&quot;) ## ## Smoothing parameters: ## alpha = 0.7065 ## ## Initial states: ## l = 8.5553 ## ## sigma: 0.2166 ## ## AIC AICc BIC ## 6.764613 7.964613 10.298775 4.2.1 The weighting function The first coefficient of the ets fit is the \\(\\alpha\\) parameter for the weighting function. alpha &lt;- coef(fit)[1] wts &lt;- alpha*(1-alpha)^(0:23) plot(1987:1964, wts/sum(wts), lwd=2, ylab=&quot;weight&quot;, xlab=&quot;&quot;, type=&quot;l&quot;) (#fig:ann.weighting)Weighting function for the simple exponential smoothing model for anchovy. 4.2.2 Decomposing your model fit Sometimes you would like to see the smoothed level that the model estimated. You can see that with plot(fit) or autoplot(fit). autoplot(fit) Figure 4.1: Decompositon of an ets fit. "],
["4-3-ets-with-trend.html", "4.3 ETS with trend", " 4.3 ETS with trend The simple exponential model has a level that evolves over time, but there is no trend, a tendency to go up or down. If a time series has a trend then we might want to include this in our forecast. Naive model with drift The naive model with drift is a simple example of a model with level and trend. This model uses the last observation as the forecast but includes a trend estimated from ALL the data. \\[\\hat{x}_{T+1} = x_T + \\bar{b}\\] where \\(\\bar{b}\\) is the mean trend or change from one time step to the next (\\(x_t-x_{t-1}\\)). \\[\\bar{b} = \\frac{1}{1-T}\\sum_{t=2}^T (x_t - x_{t-1})\\] We can fit this with forecast::Arima(). fit.rwf &lt;- forecast::Arima(anchovy87ts, order=c(0,1,0), include.drift=TRUE) fr.rwf &lt;- forecast::forecast(fit.rwf, h=5) Alternatively we can fit with rwf() which is a shortcut for the above lines. fr.rwf &lt;- forecast::rwf(anchovy87ts, h=5, drift=TRUE) A plot of the forecast shows the forecast and the prediction intervals. plot(fr.rwf) The trend seen in the blue line is estimated from the overall trend in ALL the data. coef(fit.rwf) ## drift ## 0.06577281 The trend from all the data is (last-first)/(number of steps). mean(diff(anchovy87ts)) ## [1] 0.06577281 The naive model with drift only use the latest data to choose the level for our forecast but uses all the data to choose the trend. It would make more sense to weight the more recent trends more heavily. 4.3.1 Exponential smoothing model with trend The exponential smoothing model has a level term which is an exponential weighting of past \\(x\\) and a trend term which is an exponential weighting of past trends \\(x_t - x_{t-1}\\). \\[\\hat{x}_{T+1} = l_T + b_T\\] where \\(b_T\\) is a weighted average with the more recent trends given more weight. \\[b_T = \\sum_{t=2}^T \\beta (1-\\beta)^{t-2}(x_t - x_{t-1})\\] The value of \\(\\beta\\) determines how much past trends affect the trend we use in our forecast. Fit with ets() To fit an exponential smoothing model with trend, we use `model=“AAN”. fit &lt;- forecast::ets(anchovy87ts, model=&quot;AAN&quot;) fr &lt;- forecast::forecast(fit, h=5) plot(fr) Passing in “AAN”, specifies that the model must have a trend. We can also let ets() choose whether or not to include a trend by passing in “AZN”. Here is a summary of the simple ETS models and the model code for each. model “ZZZ” alternate function exponential smoothing no trend “ANN” ses() exponential smoothing with trend “AAN” holt() exponential smoothing choose trend “AZN” NA The alternate function does exactly the same fitting. It is just a ‘shortcut’. 4.3.2 Produce forecast using a previous fit Sometimes you want to estimate a forecasting model from one dataset and use that model to forecast another dataset or another area. Here is how to do that. This is the fit to the 1964-1987 data: fit1 &lt;- forecast::ets(anchovy87ts, model=&quot;ANN&quot;) Use that model with the 2000-2007 data and produce a forecast: dat &lt;- subset(greeklandings, Species==&quot;Anchovy&quot; &amp; Year&gt;=2000 &amp; Year&lt;=2007) dat &lt;- ts(dat$log.metric.tons, start=2000) fit2 &lt;- forecast::ets(dat, model=fit1) ## Model is being refit with current smoothing parameters but initial states are being re-estimated. ## Set &#39;use.initial.values=TRUE&#39; if you want to re-use existing initial values. fr2 &lt;- forecast::forecast(fit2, h=5) plot(fr2) "],
["4-4-forecast-performance.html", "4.4 Forecast performance", " 4.4 Forecast performance We can evaluate the forecast performance with forecasts of our test data or we can use all the data and use time-series cross-validation. Let’s start with the former. 4.4.1 Test forecast performance Test against a test data set We will fit an an exponential smoothing model with trend to the training data and make a forecast for the years that we ‘held out’. fit1 &lt;- forecast::ets(traindat, model=&quot;AAN&quot;) h=length(testdat) fr &lt;- forecast::forecast(fit1, h=h) plot(fr) points(testdat, pch=2, col=&quot;red&quot;) legend(&quot;topleft&quot;, c(&quot;forecast&quot;,&quot;actual&quot;), pch=c(20,2), col=c(&quot;blue&quot;,&quot;red&quot;)) We can calculate a variety of forecast error metrics with forecast::accuracy(fr, testdat) ## ME RMSE MAE MPE MAPE MASE ## Training set 0.0155561 0.1788989 0.1442712 0.1272938 1.600532 0.7720807 ## Test set -0.5001701 0.5384355 0.5001701 -5.1678506 5.167851 2.6767060 ## ACF1 Theil&#39;s U ## Training set -0.008371542 NA ## Test set -0.500000000 2.690911 We would now repeat this for all the models in our candidate set and choose the model with the best forecast performance. Test using time-series cross-validation Another approach is to use all the data and test a series of forecasts made by fitting the model to different lengths of the data. In this approach, we don’t have test data. Instead we will use all the data for fitting and for forecast testing. We will redefine traindat as all our Anchovy data. tsCV() function We will use the tsCV() function. We need to define a function that returns a forecast. far2 &lt;- function(x, h, model){ fit &lt;- ets(x, model=model) forecast(fit, h=h) } Now we can use tsCV() to run our far2() function to a series of training data sets. We will specify that a NEW ets model be estimated for each training set. We are not using the weighting estimated for the whole data set but estimating the weighting new for each set. The e are our forecast errors for all the forecasts that we did with the data. e &lt;- forecast::tsCV(traindat, far2, h=1, model=&quot;AAN&quot;) e ## Time Series: ## Start = 1964 ## End = 1989 ## Frequency = 1 ## [1] -0.245378390 0.366852341 0.419678595 -0.414861770 -0.152727933 ## [6] -0.183775208 -0.013799590 0.308433377 -0.017680471 -0.329690537 ## [11] -0.353441463 0.266143346 -0.110848616 -0.005227309 0.157821831 ## [16] 0.196184446 0.008135667 0.326024067 0.085160559 0.312668447 ## [21] 0.246437781 0.117274740 0.292601670 -0.300814605 -0.406118961 ## [26] NA Let’s look at the first few e so we see exactly with tsCV() is doing. e[2] ## [1] 0.3668523 This uses training data from \\(t=1\\) to \\(t=2\\) so fits an ets to the first two data points alone. Then it creates a forecast for \\(t=3\\) and compares that forecast to the actual value observed for \\(t=3\\). TT &lt;- 2 # end of the temp training data temp &lt;- traindat[1:TT] fit.temp &lt;- forecast::ets(temp, model=&quot;AAN&quot;) fr.temp &lt;- forecast::forecast(fit.temp, h=1) traindat[TT+1] - fr.temp$mean ## Time Series: ## Start = 3 ## End = 3 ## Frequency = 1 ## [1] 0.3668523 e[3] ## [1] 0.4196786 This uses training data from \\(t=1\\) to \\(t=2\\) so fits an ets to the first two data points alone. Then it creates a forecast for \\(t=3\\) and compares that forecast to the actual value observed for \\(t=3\\). TT &lt;- 3 # end of the temp training data temp &lt;- traindat[1:TT] fit.temp &lt;- forecast::ets(temp, model=&quot;AAN&quot;) fr.temp &lt;- forecast::forecast(fit.temp, h=1) traindat[TT+1] - fr.temp$mean ## Time Series: ## Start = 4 ## End = 4 ## Frequency = 1 ## [1] 0.4196786 Forecast accuracy metrics Once we have the errors from tsCV(), we can compute forecast accuracy metrics. RMSE: root mean squared error rmse &lt;- sqrt(mean(e^2, na.rm=TRUE)) MAE: mean absolute error mae &lt;- mean(abs(e), na.rm=TRUE) 4.4.2 Testing a specific ets model By specifying model=\"AAN\", we estimated a new ets model (meaning new weighting) for each training set used. We might want to specify that we use only the weighting we estimated for the full data set. We do this by passing in a fit to model. The e are our forecast errors for all the forecasts that we did with the data. fit1 below is the ets estimated from all the data 1964 to 1989. Note, the code will produce a warning that it is estimating the initial value and just using the weighting. That is what we want. fit1 &lt;- forecast::ets(traindat, model=&quot;AAN&quot;) e &lt;- forecast::tsCV(traindat, far2, h=1, model=fit1) e ## Time Series: ## Start = 1964 ## End = 1989 ## Frequency = 1 ## [1] NA 0.576663901 1.031385937 0.897828249 1.033164616 ## [6] 0.935274283 0.958914499 1.265427119 -0.017241938 -0.332751184 ## [11] -0.330473144 0.255886314 -0.103926617 0.031206730 0.154727479 ## [16] 0.198328366 -0.020605522 0.297475742 0.005297401 0.264939892 ## [21] 0.196256334 0.129798648 0.335887872 -0.074017535 -0.373267163 ## [26] NA "],
["4-5-further-reading.html", "4.5 Further Reading", " 4.5 Further Reading This chapter covers a small sample of the simpler ETS models that can be fit. There are many other types of more complex ETS models and the ets() function will fit these also. Rob J Hyndman (lead on the forecast package) and George Athanasopoulos have an excellent online text on practical forecasting and exponential smoothing. Read their chapter on exponential smoothing to learn more about these models and how to use them. "],
["5-perf-testing.html", "Chapter 5 Testing forecast accuracy", " Chapter 5 Testing forecast accuracy Once you have found a set of possible forecast models, you are ready to compare forecasts from a variety of models and choose a forecast model. To quantify the forecast performance, we need to create forecasts for data that we have so that we can compare the forecast to actual data. There are two approaches to this: holding out data for testing and cross-validation.\n"],
["5-1-training-settest-set.html", "5.1 Training set/test set", " 5.1 Training set/test set One approach is to ‘hold out’ some of your data as the test data and did not use it at all in your fitting. To measure the forecast performance, you fit to your training data and test the forecast against the data in the test set. This is the approach that Stergiou and Christou used. Stergiou and Christou used 1964-1987 as their training data and tested their forecasts against 1988 and 1989. 5.1.1 Forecast versus actual We will fit to the training data and make a forecast for the test data. We can then compare the forecast to the actual values in the test data. fit1 &lt;- forecast::auto.arima(traindat) fr &lt;- forecast::forecast(fit1, h=2) fr ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 1988 10.03216 9.789577 10.27475 9.661160 10.40317 ## 1989 10.09625 9.832489 10.36001 9.692861 10.49964 Plot the forecast and compare to the actual values in 1988 and 1989. plot(fr) points(testdat, pch=2, col=&quot;red&quot;) legend(&quot;topleft&quot;, c(&quot;forecast&quot;,&quot;actual&quot;), pch=c(20,2), col=c(&quot;blue&quot;,&quot;red&quot;)) "],
["5-2-cross-validation.html", "5.2 Cross-Validation", " 5.2 Cross-Validation An alternate approach to is to use cross-validation. This approach uses windows or shorter segments of the whole time series to make a series of single forecasts. We can use either a variable length or a fixed length window. 5.2.1 Variable window For the variable length window approach applied to the Anchovy time series, we would fit the model 1964-1973 and forecast 1974, then 1964-1974 and forecast 1975, then 1964-1975 and forecast 1976, and continue up to 1964-1988 and forecast 1989. This would create 16 forecasts which we would compare to the actual landings. The window is ‘variable’ because the length of the time series used for fitting the model, keeps increasing by 1. 5.2.2 Fixed window Another approach uses a fixed window. For example, a 10-year window. 5.2.3 Cross-validation farther into the future Sometimes it makes more sense to test the performance for forecasts that are farther in the future. For example, if the data from your catch surveys takes some time to process, then you might need to make forecasts that are farther than 1 year from your last data point. In that case, there is a gap between your training data and your test data point. "],
["5-3-metrics.html", "5.3 Metrics", " 5.3 Metrics How to we quantify the difference between the forecast and the actual values in the test data set? Let’s take the example of a training set/test set. The forecast errors are the difference between the test data and the forecasts. fr.err &lt;- testdat - fr$mean fr.err ## Time Series: ## Start = 1988 ## End = 1989 ## Frequency = 1 ## [1] -0.1704302 -0.4944778 5.3.1 accuracy() function The accuracy() function in forecast provides many different metrics such as mean error, root mean square error, mean absolute error, mean percentage error, mean absolute percentage error. It requires a forecast object and a test data set that is the same length. accuracy(fr, testdat) ## ME RMSE MAE MPE MAPE MASE ## Training set -0.00473511 0.1770653 0.1438523 -0.1102259 1.588409 0.7698386 ## Test set -0.33245398 0.3698342 0.3324540 -3.4390277 3.439028 1.7791577 ## ACF1 Theil&#39;s U ## Training set -0.04312022 NA ## Test set -0.50000000 1.90214 The metrics are: ME Mean err me &lt;- mean(fr.err) me ## [1] -0.332454 RMSE Root mean squared error rmse &lt;- sqrt(mean(fr.err^2)) rmse ## [1] 0.3698342 MAE Mean absolute error mae &lt;- mean(abs(fr.err)) mae ## [1] 0.332454 MPE Mean percentage error fr.pe &lt;- 100*fr.err/testdat mpe &lt;- mean(fr.pe) mpe ## [1] -3.439028 MAPE Mean absolute percentage error mape &lt;- mean(abs(fr.pe)) mape ## [1] 3.439028 accuracy(fr, testdat)[,1:5] ## ME RMSE MAE MPE MAPE ## Training set -0.00473511 0.1770653 0.1438523 -0.1102259 1.588409 ## Test set -0.33245398 0.3698342 0.3324540 -3.4390277 3.439028 c(me, rmse, mae, mpe, mape) ## [1] -0.3324540 0.3698342 0.3324540 -3.4390277 3.4390277 5.3.2 Test multiple models Now that you have some metrics for forecast accuracy, you can compute these for all the models in your candidate set. # The model picked by auto.arima fit1 &lt;- forecast::Arima(traindat, order=c(0,1,1)) fr1 &lt;- forecast::forecast(fit1, h=2) test1 &lt;- forecast::accuracy(fr1, testdat)[2,1:5] # AR-1 fit2 &lt;- forecast::Arima(traindat, order=c(1,1,0)) fr2 &lt;- forecast::forecast(fit2, h=2) test2 &lt;- forecast::accuracy(fr2, testdat)[2,1:5] # Naive model with drift fit3 &lt;- forecast::rwf(traindat, drift=TRUE) fr3 &lt;- forecast::forecast(fit3, h=2) test3 &lt;- forecast::accuracy(fr3, testdat)[2,1:5] Show a summary ME RMSE MAE MPE MAPE (0,1,1) -0.293 0.320 0.293 -3.024 3.024 (1,1,0) -0.309 0.341 0.309 -3.200 3.200 Naive -0.483 0.510 0.483 -4.985 4.985 5.3.3 Cross-validation Computing forecast errors and performance metrics with time series cross-validation is similar to the training set/test test approach. The first step to using the tsCV() function is to define the function that returns a forecast for your model. Your function needs to take x, a time series, and h the length of the forecast. You can also have other arguments if needed. Here is an example function for a forecast from an ARIMA model. fun &lt;- function(x, h, order){ forecast::forecast(Arima(x, order=order), h=h) } We pass this into the tsCV() function. tsCV() requires our dataset and our forecast function. The arguments after the forecast function are those we included in our fun definition. tsCV() returns a time series of errors. e &lt;- forecast::tsCV(traindat, fun, h=1, order=c(0,1,1)) We then can compute performance metrics from these errors. tscv1 &lt;- c(ME=mean(e, na.rm=TRUE), RMSE=sqrt(mean(e^2, na.rm=TRUE)), MAE=mean(abs(e), na.rm=TRUE)) tscv1 ## ME RMSE MAE ## 0.1128788 0.2261706 0.1880392 Cross-validation farther in future Compare accuracy of forecasts 1 year out versus 4 years out. If h is greater than 1, then the errors are returned as a matrix with each h in a column. Column 4 is the forecast, 4 years out. e &lt;- forecast::tsCV(traindat, fun, h=4, order=c(0,1,1))[,4] #RMSE tscv4 &lt;- c(ME=mean(e, na.rm=TRUE), RMSE=sqrt(mean(e^2, na.rm=TRUE)), MAE=mean(abs(e), na.rm=TRUE)) rbind(tscv1, tscv4) ## ME RMSE MAE ## tscv1 0.1128788 0.2261706 0.1880392 ## tscv4 0.2839064 0.3812815 0.3359689 As we would expect, forecast errors are higher when we make forecasts farther into the future. Cross-validation with a fixed window Compare accuracy of forecasts with a fixed 10-year window and 1-year out forecasts. e &lt;- forecast::tsCV(traindat, fun, h=1, order=c(0,1,1), window=10) #RMSE tscvf1 &lt;- c(ME=mean(e, na.rm=TRUE), RMSE=sqrt(mean(e^2, na.rm=TRUE)), MAE=mean(abs(e), na.rm=TRUE)) tscvf1 ## ME RMSE MAE ## 0.1387670 0.2286572 0.1942840 All the forecasts tests together Here are all 4 types of forecasts tests together. There is not right approach. Time series cross-validation has the advantage that you test many more forecasts and use all your data. comp.tab &lt;- rbind(train.test=test1[c(&quot;ME&quot;,&quot;RMSE&quot;,&quot;MAE&quot;)], tsCV.variable1=tscv1, tsCV.variable4=tscv4, tsCV.fixed1=tscvf1) knitr::kable(comp.tab, format=&quot;html&quot;) ME RMSE MAE train.test -0.2925326 0.3201093 0.2925326 tsCV.variable1 0.1128788 0.2261706 0.1880392 tsCV.variable4 0.2839064 0.3812815 0.3359689 tsCV.fixed1 0.1387670 0.2286572 0.1942840 "],
["5-4-candidate-model-set.html", "5.4 Candidate model set", " 5.4 Candidate model set Once you have explored a variety of forecasting models you can come up with a candidate set of models along with a set of null models. Here is our candidate models for the anchovy along with the code to fit and create a forecast from each model. Exponential smoothing model with trend fit &lt;- forecast::ets(traindat, model=&quot;AAN&quot;) fr &lt;- forecast::forecast(fit, h=1) Exponential smoothing model no trend fit &lt;- forecast::ets(traindat, model=&quot;ANN&quot;) fr &lt;- forecast::forecast(fit, h=1) ARIMA(0,1,1) with drift (best) fit &lt;- forecast::Arima(traindat, order(0,1,1), include.drift=TRUE) fr &lt;- forecast::forecast(fit, h=1) ARIMA(2,1,0) with drift (within 2 AIC of best) fit &lt;- forecast::Arima(traindat, order(2,1,0), include.drift=TRUE) fr &lt;- forecast::forecast(fit, h=1) Time-varying regression with linear time traindat$t &lt;- 1:24 fit &lt;- lm(log.metric.tons ~ t, data=traindat) fr &lt;- forecast::forecast(fit, newdata=data.frame(t=25)) We also need to include null models in our candidate set. Null models Naive no trend fit &lt;- forecast::Arima(traindat, order(0,1,0)) fr &lt;- forecast::forecast(fit, h=1) # or simply fr &lt;- forecast::rwf(traindat, h=1) Naive with trend fit &lt;- forecast::Arima(traindat, order(0,1,0), include.drift=TRUE) fr &lt;- forecast::forecast(fit, h=1) # or simply fr &lt;- forecast::rwf(traindat, drift=TRUE, h=1) Average or mean fit &lt;- forecast::Arima(traindat, order(0,0,0)) fr &lt;- forecast::forecast(fit, h=1) "],
["5-5-testing-the-candidate-model-set.html", "5.5 Testing the candidate model set", " 5.5 Testing the candidate model set With a set of candidate models, we can prepare tables showing the forecast performance for each model. For each model, we will do the same steps: Fit the model Create forecasts for a test data set or use cross-validation Compute forecast accuracy metrics for the forecasts Note when you compare models, you can use both ‘training data/test data’ and use time-series cross-validation, but report the metrics in separate columns. Example, ‘RMSE from tsCV’ and ‘RMSE from test data’. 5.5.1 Fit each of our candidate models We will define the training data as 1964 to 1987 and the test data as 1988 and 1989. The full data is 1964 to 1989. fulldat &lt;- window(anchovyts, 1964, 1989) traindat &lt;- window(anchovyts, 1964, 1987) testdat &lt;- window(anchovyts, 1988, 1989) We will store our fits and forecasts in a list for easy access. fun.list is the function to pass to tsCV(). fit.list &lt;- list() fr.list &lt;- list() fun.list &lt;- list() n.fr &lt;- length(testdat) For each model, we will fit, forecast, and define a forecast function. Exponential smoothing model with trend modelname &lt;- &quot;ETS w trend&quot; fit &lt;- ets(traindat, model=&quot;AAN&quot;) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ forecast(ets(x, model=&quot;AAN&quot;), h=h) } Exponential smoothing model no trend modelname &lt;- &quot;ETS no trend&quot; fit &lt;- ets(traindat, model=&quot;ANN&quot;) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ forecast(ets(x, model=&quot;ANN&quot;), h=h) } ARIMA(0,1,1) with drift (best) modelname &lt;- &quot;ARIMA(0,1,1) w drift&quot; fit &lt;- Arima(traindat, order=c(0,1,1), include.drift=TRUE) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ forecast(Arima(x, order=c(0,1,1), include.drift=TRUE),h=h) } ARIMA(2,1,0) with drift (within 2 AIC of best) modelname &lt;- &quot;ARIMA(2,1,0) w drift&quot; fit &lt;- Arima(traindat, order=c(2,1,0), include.drift=TRUE) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ forecast(Arima(x, order=c(2,1,0), include.drift=TRUE),h=h) } Time-varying regression with linear time TT &lt;- length(traindat) #make a data.frame for lm dat &lt;- data.frame(log.metric.tons=traindat, t=1:TT) modelname &lt;- &quot;TV linear regression&quot; fit &lt;- lm(log.metric.tons ~ t, data=dat) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, newdata=data.frame(t=TT+1:n.fr)) fun.list[[modelname]] &lt;- function(x, h){ TT &lt;- length(x) dat &lt;- data.frame(log.metric.tons=x, t=1:TT) ft &lt;- lm(log.metric.tons ~ t, data=dat) forecast(ft, newdata=data.frame(t=TT+h)) } Naive no trend modelname &lt;- &quot;Naive&quot; fit &lt;- Arima(traindat, order=c(0,1,0)) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ rwf(x,h=h) } Naive with trend modelname &lt;- &quot;Naive w trend&quot; fit &lt;- Arima(traindat, order=c(0,1,0), include.drift=TRUE) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ rwf(x, drift=TRUE, h=h) } Average or mean modelname &lt;- &quot;Average&quot; fit &lt;- Arima(traindat, order=c(0,0,0)) fit.list[[modelname]] &lt;- fit fr.list[[modelname]] &lt;- forecast(fit, h=n.fr) fun.list[[modelname]] &lt;- function(x, h){ forecast(Arima(x, order=c(0,0,0)),h=h) } "],
["5-6-models-fit.html", "5.6 Models fit", " 5.6 Models fit Now we can use names() to see the models that we have fit. If we want to add more, we use the code above as a template. modelnames &lt;- names(fit.list) modelnames ## [1] &quot;ETS w trend&quot; &quot;ETS no trend&quot; &quot;ARIMA(0,1,1) w drift&quot; ## [4] &quot;ARIMA(2,1,0) w drift&quot; &quot;TV linear regression&quot; &quot;Naive&quot; ## [7] &quot;Naive w trend&quot; &quot;Average&quot; 5.6.1 Metrics for each model We will run the models and compute the forecast metrics for each and put in a table. restab &lt;- data.frame(model=modelnames, RMSE=NA, ME=NA, tsCV.RMSE=NA, AIC=NA, BIC=NA, stringsAsFactors = FALSE) for(i in modelnames){ fit &lt;- fit.list[[i]] fr &lt;- fr.list[[i]] restab$RMSE[restab$model==i] &lt;- accuracy(fr, testdat)[&quot;Test set&quot;,&quot;RMSE&quot;] restab$ME[restab$model==i] &lt;- accuracy(fr, testdat)[&quot;Test set&quot;,&quot;ME&quot;] e &lt;- tsCV(traindat, fun.list[[i]], h=1) restab$tsCV.RMSE[restab$model==i] &lt;- sqrt(mean(e^2, na.rm=TRUE)) restab$AIC[restab$model==i] &lt;- AIC(fit) restab$BIC[restab$model==i] &lt;- BIC(fit) } Add on \\(\\Delta\\)AIC and \\(\\Delta\\)BIC. Sort by \\(\\Delta\\)AIC and format to have 3 digits. restab$DeltaAIC &lt;- restab$AIC-min(restab$AIC) restab$DeltaBIC &lt;- restab$BIC-min(restab$BIC) restab &lt;- restab[order(restab$DeltaAIC),] resfor &lt;- format(restab, digits=3, trim=TRUE) Bold the minimum values in each column so they are easy to spot. for(i in colnames(resfor)){ if(class(restab[,i])==&quot;character&quot;) next if(i!=&quot;ME&quot;) testval &lt;- restab[,i] else testval &lt;- abs(restab[,i]) theminrow &lt;- which(testval==min(testval)) resfor[theminrow, i] &lt;- paste0(&quot;**&quot;,resfor[theminrow,i],&quot;**&quot;) } This is the table of FORECAST performance metrics. Not how well it fits the data, but how well it forecasts out of the data. RSME and ME are for the 2 data points in 1988 and 1989 that were held out for testing. tsCV.RMSE is the RSME for the time-series crossvalidation that makes a series of forecasts for each point in the data. AIC and BIC are information criteria, which are a measure of data support for each model. knitr::kable(resfor) model RMSE ME tsCV.RMSE AIC BIC DeltaAIC DeltaBIC 5 TV linear regression 0.195 -0.114 0.247 -7.00 -3.4611 0.00000 0.123 3 ARIMA(0,1,1) w drift 0.370 -0.332 0.231 -6.99 -3.5844 0.00443 0.000 4 ARIMA(2,1,0) w drift 0.381 -0.347 0.224 -6.08 -1.5399 0.91340 2.044 7 Naive w trend 0.510 -0.483 0.239 -2.18 0.0883 4.81255 3.673 6 Naive 0.406 -0.384 0.222 -2.06 -0.9247 4.93505 2.660 1 ETS w trend 0.538 -0.500 0.251 3.67 9.5587 10.66374 13.143 2 ETS no trend 0.317 -0.289 0.222 6.76 10.2988 13.75990 13.883 8 Average 0.656 0.643 0.476 33.04 35.3924 40.03162 38.977 "],
["6-covariates.html", "Chapter 6 Covariates", " Chapter 6 Covariates Often we want to explain the variability in our data using covariates or exogenous variables. We may want to do this in order to create forecasts using information from the covariates in time step \\(t-1\\) or \\(t\\) to help forecast at time \\(t\\). Or we may want to understand what causes variability in our data in order to help understand the underlying process. We can include covariates in the time-varying regression model and the ARIMA models. We cannot include covariates in an exponential smoothing model. That doesn’t make sense as a exponential model is a type of filter of the data not a ‘process’ model. In this chapter, I show a number of approaches for including covariates in a multivariate regression model (MREG) with temporally independent errors. This is not a time series model per se, but rather a multivariate regression applied to time-ordered data. MREG models with auto-regressive errors and auto-regressive models with covariates will be addressed in a separate chapter. I illustrate a variety of approaches for developing a set of covariate for a MREG model. The first approach is variable selection, which was the approach used by Stergiou and Christou for their MREG models (6.3). The other approaches are penalized regression (6.4), relative importance metrics (6.5), and orthogonalization (6.6). These approaches all deal with the problem of selecting a set of covariates to include in your model. Before discussing models with covariates, I will show a variety of approaches for evaluating the collinearity in your covariate set. Collinearity will dramatically affect your inferences concerning the effect of your covariates and needs to be assessed before you begin modeling.\n"],
["6-1-covariates-used-in-stergiou-and-christou.html", "6.1 Covariates used in Stergiou and Christou", " 6.1 Covariates used in Stergiou and Christou Stergiou and Christou used five environmental covariates: air temperature (air), sea-level pressure (slp), sea surface temperature (sst), vertical wind speed (vwnd), and wind speed cubed (wspd3). I downloaded monthly values for these covariates from the three 1 degree boxes used by Stergiou and Christou from the ICOADS database. I then computed a yearly average over all months in the three boxes. These yearly average environmental covariates are in covsmean.year, which is part of landings in the FishForecast package. require(FishForecast) colnames(ecovsmean.year) ## [1] &quot;Year&quot; &quot;air.degC&quot; &quot;slp.millibars&quot; &quot;sst.degC&quot; ## [5] &quot;vwnd.m/s&quot; &quot;wspd3.m3/s3&quot; The covariates are those in Stergiou and Christou with the following differences. I used the ICOADS data not the COADS data. The boxes are 1 degree but on 1 degree centers not 0.5 centers. Thus the box is 39.5-40.5 not 39-40. ICOADS does not include ‘vertical wind’. I used NS winds which may be different. The code to download the ICOADS data is in the appendix. In addition to the environmental covariates, Stergiou and Christou used many covariates of fishing effort for trawlers, purse seiners, beach seiners, other coastal boats and demersal (sum of trawlers, beach seiners and other coastal boats). For each fishery type, they used data on number of fishers (FI), number of boats (BO), total engine horse power (HP), total boat tonnage (TO). They also used an economic variable: value (VA) of catch for trawlers, purse seiners, beach seiners, other coastal boats. These fishery covariates were extracted from the Greek Statistical Reports (1.1.1). colnames(greekfish.cov) ## [1] &quot;Year&quot; &quot;Boats.BO&quot; &quot;Trawlers.BOT&quot; ## [4] &quot;Purse.seiners.BOP&quot; &quot;Beach.seiners.BOB&quot; &quot;Other.BOC&quot; ## [7] &quot;Demersal.BOD&quot; &quot;Fishers.FI&quot; &quot;Trawlers.FIT&quot; ## [10] &quot;Purse.seiners.FIP&quot; &quot;Beach.seiners.FIB&quot; &quot;Other.FIC&quot; ## [13] &quot;Demersal.FID&quot; &quot;Horsepower.HP&quot; &quot;Trawler.HPT&quot; ## [16] &quot;Purse.seiners.HPP&quot; &quot;Beach.seiners.HPB&quot; &quot;Other.HPC&quot; ## [19] &quot;Demersal.HPD&quot; &quot;Trawler.VAT&quot; &quot;Purse.seiners.VAP&quot; ## [22] &quot;Beach.seiners.VAB&quot; &quot;Other.VAC&quot; &quot;Tonnage.TO&quot; ## [25] &quot;Trawlers.TOT&quot; &quot;Purse.seiners.TOP&quot; For anchovy, the fishery effort metrics from the purse seine fishery were used. Lastly, biological covariates were included which were the landings of other species. Stergiou and Christou state (page 118) that the other species modeled by VAR (page 114) was included. This would imply that sardine was used as an explanatory variable. However in Table 3 (page 119), it appears that Trachurus (Horse mackerel) was included. It is not clear if sardine was also included but not chosen as an important variable. I included Trachurus and not sardine as the biological explanatory variable. Preparing the data frame We will model anchovy landings as the response variable. The covariates are lagged by one year, following Stergiou and Christou. This means that the catch in year \\(t\\) is regressed against the covariates in year \\(t-1\\). We set up our data frame as follows. We use the 1965 to 1987 catch data as the response. We use 1964 to 1986, so year prior, for all the explanatory variables and we log transform the explanatory variables (following Stergiou and Christou). We use \\(t\\) 1 to 23 as a “year” covariate. Our data frame will have the following columns: colnames(df) ## [1] &quot;anchovy&quot; &quot;Year&quot; &quot;Trachurus&quot; &quot;air&quot; &quot;slp&quot; &quot;sst&quot; ## [7] &quot;vwnd&quot; &quot;wspd3&quot; &quot;BOP&quot; &quot;FIP&quot; &quot;HPP&quot; &quot;TOP&quot; In total, there are 11 covariates and 23 years of data—which is not much data per explanatory variable. Section @ref(cov.df) shows the R code to create the df data frame with the response variable and all the explanatory variables. For most of the analyses, we will use the untransformed variables, however for some analyses, we will want the effect sizes (the estimated \\(\\beta\\)’s) to be on the same scale. For these analyses, we will use the z-scored variables, which will be stored in data frame dfz. z-scoring removes the mean and normalizes the variance to 1. Here is a loop to demean and rescale our data frame. dfz &lt;- df n &lt;- nrow(df) for(i in colnames(df)){ pop_sd &lt;- sd(df[,i])*sqrt((n-1)/n) pop_mean &lt;- mean(df[,i]) dfz[,i] &lt;- (df[,i]-pop_mean)/pop_sd } The function scale() will also do a scaling to the unbiased variance instead of the sample variance (divide by \\(n-1\\) instead of \\(n\\)) and will return a matrix. We will use dfz which is scaled to the sample variance as we will need this for the chapter on Principal Components Regression. df.scale &lt;- as.data.frame(scale(df)) 6.1.1 Creating the data frame for model fitting Code to make the df data frame used in the model fitting functions. # response df &lt;- data.frame(anchovy=anchovy$log.metric.tons, Year=anchovy$Year) Year1 &lt;- df$Year[1] Year2 &lt;- df$Year[length(df$Year)] df &lt;- subset(df, Year&gt;=Year1+1 &amp; Year&lt;=Year2) # biological covariates df.bio &lt;- subset(greeklandings, Species==&quot;Horse.mackerel&quot;)[,c(&quot;Year&quot;,&quot;log.metric.tons&quot;)] df.bio &lt;- subset(df.bio, Year&gt;=Year1 &amp; Year&lt;=Year2-1)[,-1,drop=FALSE] # [,-1] to remove year colnames(df.bio) &lt;- &quot;Trachurus&quot; # environmental covariates ecovsmean.year[,&quot;vwnd.m/s&quot;]&lt;- abs(ecovsmean.year[,&quot;vwnd.m/s&quot;]) df.env &lt;- log(subset(ecovsmean.year, Year&gt;=Year1 &amp; Year&lt;=Year2-1)[,-1]) # fishing effort df.fish &lt;- log(subset(greekfish.cov, Year&gt;=Year1 &amp; Year&lt;=Year2-1)[,-1]) purse.cols &lt;- stringr::str_detect(colnames(df.fish),&quot;Purse.seiners&quot;) df.fish &lt;- df.fish[,purse.cols] df.fish &lt;- df.fish[!(colnames(df.fish)==&quot;Purse.seiners.VAP&quot;)] # assemble df &lt;- data.frame( df, df.bio, df.env, df.fish ) df$Year &lt;- df$Year-df$Year[1]+1 colnames(df) &lt;- sapply(colnames(df), function(x){rev(stringr::str_split(x,&quot;Purse.seiners.&quot;)[[1]])[1]}) colnames(df) &lt;- sapply(colnames(df), function(x){stringr::str_split(x,&quot;[.]&quot;)[[1]][1]}) df &lt;- df[,colnames(df)!=&quot;VAP&quot;] # all the data to 2007 df.full &lt;- df # only training data df &lt;- subset(df, Year&gt;=1965-1964 &amp; Year&lt;=1987-1964) save(df, df.full, file=&quot;MREG_Data.RData&quot;) "],
["6-2-collinear.html", "6.2 Collinearity", " 6.2 Collinearity Collinearity is near-linear relationships among the explanatory variables. Collinearity causes many problems such as inflated standard errors of the coefficients and correspondingly unbiased but highly imprecise estimates of the coefficients, false p-values, and poor predictive accuracy of the model. Thus it is important to evaluate the level of collinearity in your explanatory variables. library(ggplot2) library(car) library(Hmisc) library(corrplot) library(olsrr) Pairs plot One way to see this is visually is with the pairs() plot. A pairs plot of fishing effort covariates reveals high correlations between Year, HPP and TOP. pairs(df[,c(2,9:12)]) The environmental covariates look generally ok. pairs(df[,c(2,4:8)]) Another way that we can visualize the problem is by looking at the correlation matrix using the corrplot package. library(corrplot) X &lt;- as.matrix(df[,colnames(df)!=&quot;anchovy&quot;]) corrplot::corrplot(cor(X)) Variance inflation factors Another way is to look for collinearity is to compute the variance inflation factors (VIF). The variance inflation factor is an estimate of how much larger the variance of a coefficient estimate is compared to if the variable were uncorrelated with the other explanatory variables in the model. If the VIF of variable \\(i\\) is \\(z\\), then the standard error of the \\(\\beta_i\\) for variable \\(i\\) is \\(\\sqrt{z}\\) times larger than if variable \\(i\\) were uncorrelated with the other variables. For example, if VIF=10, the standard error of the coefficient estimate is 3.16 times larger (inflated). The rule of thumb is that any of the variables with VIF greater than 10 have collinearity problems. The vif() function in the car package will compute VIFs for us. full &lt;- lm(anchovy ~ ., data=df) car::vif(full) ## Year Trachurus air slp sst vwnd wspd3 ## 103.922970 18.140279 3.733963 3.324463 2.476689 2.010485 1.909992 ## BOP FIP HPP TOP ## 13.676208 8.836446 63.507170 125.295727 The ols_vif_tol() function in the olsrr package also computes the VIF. olsrr::ols_vif_tol(full) (#tab:vif.olsrr) VariablesToleranceVIF Year0.00962104&nbsp;&nbsp;&nbsp; Trachurus0.0551&nbsp;18.1&nbsp; air0.268&nbsp;&nbsp;3.73 slp0.301&nbsp;&nbsp;3.32 sst0.404&nbsp;&nbsp;2.48 vwnd0.497&nbsp;&nbsp;2.01 wspd30.524&nbsp;&nbsp;1.91 BOP0.0731&nbsp;13.7&nbsp; FIP0.113&nbsp;&nbsp;8.84 HPP0.0157&nbsp;63.5&nbsp; TOP0.00798125&nbsp;&nbsp;&nbsp; This shows that Year, HPP and TOP have severe collinearity problems, and BOP and Trachusus also have collinearity issues, though lesser. Condition indices Condition indices are computed from the eigenvalues of the correlation matrix of the variates. The size of the index will be greatly affected by whether you have standardized the variance of your covariates, unlike the other tests described here. \\[ci = \\sqrt{max(eigenvalue)/eigenvalue}\\] vars &lt;- as.matrix(dfz[,-1]) res &lt;- eigen(crossprod(vars))$values sqrt(max(res)/res) ## [1] 1.000000 1.506975 2.235652 2.332424 3.025852 3.895303 4.753285 ## [8] 5.419310 7.977486 20.115739 35.515852 vars &lt;- as.matrix(dfz[,-1]) res &lt;- eigen(crossprod(vars))$values sqrt(max(res)/res) ## [1] 1.000000 1.506975 2.235652 2.332424 3.025852 3.895303 4.753285 ## [8] 5.419310 7.977486 20.115739 35.515852 See the information from the olsrr package on condition indices on how to use condition indices to spot collinearity. Basically you are looking for condition indices greater than 30 whether the proportion of variance for the covariate is greater than 0.5. In the table below, this criteria identifies Year, BOP, and TOP. Note that the test was done with the standardized covariates (dfz). model &lt;- lm(anchovy ~ ., data=dfz) round(olsrr::ols_eigen_cindex(model), digit=2) Table 6.1: EigenvalueCondition IndexinterceptYearTrachurusairslpsstvwndwspd3BOPFIPHPPTOP 5.251&nbsp;&nbsp;&nbsp;00&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.010&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 2.311.5100&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.030&nbsp;&nbsp;&nbsp;0.040.030.020&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 1.052.2400&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.010&nbsp;&nbsp;&nbsp;0.130.170&nbsp;&nbsp;&nbsp;0.020&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;2.2910&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 0.962.3300&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.050.020.1&nbsp;0.210.010.010&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 0.573.0300&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.030.150.240.120.010.020&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 0.353.9&nbsp;00&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.140.130.240.040.160.010.090&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 0.234.7500&nbsp;&nbsp;&nbsp;0.020.330.150.150.450.070.010.030&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 0.185.4200.010.180.090.090.080.010&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0.030.010&nbsp;&nbsp;&nbsp; 0.087.9800.020.040.230.290.090.010.160.4&nbsp;0.120&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp; 0.0120.1&nbsp;00.050.290.020.040.070.040.130&nbsp;&nbsp;&nbsp;0.670.640.15 0&nbsp;&nbsp;&nbsp;35.5&nbsp;00.920.470.120.090.060.070.060.550.010.350.84 redun() The Hmisc library also has a redundancy function (redun()) that can help identify which variables are redundant. This identifies variables that can be explained with an \\(R^2&gt;0.9\\) by a linear (or non-linear) combination of other variables. We are fitting a linear model, so we set nk=0 to force redun() to only look at linear combinations. We use redun() only on the explanatory variables and thus remove the first column, which is our response variable (anchovy). a &lt;- Hmisc::redun(~ .,data=df[,-1], nk=0) a$Out ## [1] &quot;TOP&quot; &quot;HPP&quot; This indicates that TOP and HPP can be explained by the other variables. 6.2.1 Effect of collinearity One thing that happens when we have collinearity is that we will get “complementary” (negative matched by positive) and very large coefficients in the variables that are collinear. We see this when we fit a linear regression with all the variables. I use the z-scored data so that the effect sizes (x-axis) are on the same scale. The Year coefficients is very large and the TOP and HPP coefficients are negative and very large. If we look at the fit, we see the at the standard errors for Year, TOP and HPP are very large. The p-value for Year is significant, however in the presence of severe collinearity, reported p-values should not be trusted. summary(fit.full) ## ## Call: ## lm(formula = anchovy ~ ., data = dfz) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.4112 -0.1633 -0.0441 0.1459 0.5009 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -9.175e-15 7.003e-02 0.000 1.0000 ## Year 2.118e+00 7.139e-01 2.966 0.0128 * ## Trachurus -6.717e-02 2.983e-01 -0.225 0.8260 ## air 2.987e-01 1.353e-01 2.207 0.0495 * ## slp -5.023e-02 1.277e-01 -0.393 0.7016 ## sst -7.250e-02 1.102e-01 -0.658 0.5242 ## vwnd 1.530e-01 9.930e-02 1.540 0.1517 ## wspd3 6.086e-02 9.679e-02 0.629 0.5423 ## BOP 3.137e-01 2.590e-01 1.211 0.2512 ## FIP 1.347e-01 2.082e-01 0.647 0.5309 ## HPP -5.202e-01 5.581e-01 -0.932 0.3713 ## TOP -8.068e-01 7.839e-01 -1.029 0.3255 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3359 on 11 degrees of freedom ## Multiple R-squared: 0.946,\tAdjusted R-squared: 0.8921 ## F-statistic: 17.53 on 11 and 11 DF, p-value: 2.073e-05 Stergiou and Christou do not state how (if at all) they address the collinearity in the explanatory variables, but it is clearly present. In the next chapter, I will show how to develop a multivariate regression model using variable selection. This is the approach used by Stergiou and Christou. Keep in mind that variable selection will not perform well when there is collinearity in your covariates and that variable selection is prone to over-fitting and selecting covariates due to chance. "],
["6-3-MREGVAR.html", "6.3 Variable selection", " 6.3 Variable selection In this chapter, I will illustrate developing a forecasting model using a multivariate regression (MREG). I will show the variable selection approach that Stergiou and Christou used to develop MREG models. More background on the methods discussed in this chapter can be found in the references in the endnotes.1 2 3 4 5. A multivariate linear regression model with Gaussian errors takes the form: \\[\\begin{equation} \\begin{gathered} x_t = \\alpha + \\phi_1 c_{t,1} + \\phi_2 c_{t,2} + \\dots + e_t \\\\ e_t \\sim N(0,\\sigma) \\end{gathered} \\end{equation}\\] In R, we can fit this model with lm(), which uses ordinary least squares (OLS). For model selection (determining what explanatory variables to include), there are a variety of approaches we can take. I will show approaches that use a few different packages. library(ggplot2) library(MASS) library(car) library(glmnet) library(stringr) library(caret) library(leaps) library(forecast) library(olsrr) 6.3.1 Model selection with stepwise variable selection Stergiou and Christou state that the covariates to include were selected with stepwise variable selection. Stepwise variable selection is a type of automatic variable selection. Stepwise variable selection has many statistical problems and the problems are worse when the covariates are collinear as they are in our case (see this link for a review of the problems with stepwise variable selection). The gist of the problem is one of over-fitting. A stepwise selection procedure will tend to choose variables that, by chance, have large coefficients. With only 23 data points and high collinearity, this is likely to be a rather large problem for our dataset. As we saw, collinearity tends to cause very large positive effect sizes offset by large negative effect sizes. However I use stepwise variable selection here to replicate Stergiou and Christou. I will follow this with an example of other more robust approaches to model selection for linear regression. Stergiou and Christou do not give specifics on how they implemented stepwise variable selection. Stepwise variable selection refers to a forward-backward search, however there are many ways we can implement this and different approaches give different answers. The starting model in particular will have a large effect on the ending model. step() When using the step() function in the stats package (and the related stepAIC() function in the MASS package) , we specify the starting model and the scope of the search, i.e., the smallest model and the largest model. We set direction equal to “both” to specify stepwise variable selection. We also need to specify the selection criteria. The default is to use AIC. Let’s start with a search that starts with a full model which has all the explanatory variables. The first argument to step() is the starting model and scope specifies the maximum and minimum models as a list. direction=\"both\" is stepwise variable selection. trace=0 turns off the reporting. null &lt;- lm(anchovy ~ 1, data=df) full &lt;- lm(anchovy ~ ., data=df) step.full &lt;- step(full, scope=list(lower=null, upper=full), direction=&quot;both&quot;, trace = 0) step.full ## ## Call: ## lm(formula = anchovy ~ Year + air + vwnd + BOP + FIP + TOP, data = df) ## ## Coefficients: ## (Intercept) Year air vwnd BOP FIP ## -5.6500 0.1198 3.7000 0.1320 1.8051 1.0189 ## TOP ## -1.7894 We can also apply step() with the caret package: step.caret &lt;- caret::train(anchovy ~ ., data = df, method = &quot;lmStepAIC&quot;, direction = &quot;both&quot;, trace = FALSE ) ## Warning: attempting model selection on an essentially perfect fit is nonsense ## Warning: attempting model selection on an essentially perfect fit is nonsense step.caret$finalModel ## ## Call: ## lm(formula = .outcome ~ Year + air + vwnd + BOP + FIP + TOP, ## data = dat) ## ## Coefficients: ## (Intercept) Year air vwnd BOP FIP ## -5.6500 0.1198 3.7000 0.1320 1.8051 1.0189 ## TOP ## -1.7894 Note that method=\"lmStepAIC\" in the train() function will always start with the full model. The AIC for this model is -19.6. This is a larger model than that reported in Table 3 (page 119) of Stergiou and Christou. The model in Table 3 includes only Year, Trachurus catch, SST, and FIP. The model selected by step() starting from the full model includes Year, Trachurus catch, air temperature, vertical wind, BOP, FIP and TOP. Let’s repeat but start the search with the smallest model. null &lt;- lm(anchovy ~ 1, data=df) full &lt;- lm(anchovy ~ ., data=df) step.null &lt;- step(null, scope=list(lower=null, upper=full), direction=&quot;both&quot;, trace = 0) step.null ## ## Call: ## lm(formula = anchovy ~ Year + FIP + Trachurus + air, data = df) ## ## Coefficients: ## (Intercept) Year FIP Trachurus air ## -0.51874 0.08663 0.81058 -0.28602 1.62735 This model has an AIC of -18.7. This AIC is larger (worse), which illustrates that you need to be careful how you set up the search. This selected model is very similar to that in Table 3 except that air temperature instead of SST is selected. Air temperature and SST are correlated, however. The air temperature is removed from the best model if we use BIC as the model selection criteria. This is done by setting k=log(n) where \\(n\\) is sample size. step.null.bic &lt;- step(null, scope=list(lower=null, upper=full), direction=&quot;both&quot;, trace = 0, k=log(nrow(df))) step.null.bic ## ## Call: ## lm(formula = anchovy ~ Year + FIP + Trachurus, data = df) ## ## Coefficients: ## (Intercept) Year FIP Trachurus ## 2.81733 0.08836 0.98541 -0.30092 We can also do stepwise variable selection using the leaps package. However, the algorithm or starting model is different than for step() and the results are correspondingly different. The top row in the plot shows the included (black) variables: Year, Trachurus, air, vwnd, FIP. The results are similar to step() starting from the full model but not identical. See the next section for a brief introduction to the leaps package. models &lt;- leaps::regsubsets(anchovy~., data = df, nvmax =11, method = &quot;seqrep&quot;, nbest=1) plot(models, scale=&quot;bic&quot;) leaps() We can use the leaps package to do a full search of the model space. The function leaps::regsubsets() will find the nbest models of size (number of explanatory variables) 1 to nvmax using different types of searches: exhaustive, forward, backward, and stepwise variable selection. We can then plot these best models of each size against a criteria. such as BIC. leaps allows us to plot against BIC, Cp (asymptotically the same as AIC and LOOCV), \\(R^2\\) and adjusted \\(R^2\\). Each row in the plot is a model. The dark shading shows which variables are in the model. On the y-axis, farther away from the x-axis is better, so the models (rows) at the top of the plot are the best models. Let’s start with an exhaustive search and show only the best model of each size, where size is the number of explanatory variables in the model. models &lt;- leaps::regsubsets(anchovy~., data = df, nvmax = 11, nbest=1, method = &quot;exhaustive&quot;) plot(models, scale=&quot;bic&quot;) We see that when we use BIC as the selection criteria, the best model has Year, Trachurus, and FIP. Let’s look at more than one model for each model size. Let’s take the top 3 models for each model size and look at their BICs. models &lt;- leaps::regsubsets(anchovy~., data = df, nvmax = 11, nbest=3, method = &quot;exhaustive&quot;) plot(models, scale=&quot;bic&quot;) We can plot the BIC for each size of model also. smodels = summary(models) nvar &lt;- apply(smodels$which,1,sum)-1 plot(nvar, smodels$bic, xlab = &quot;Number of Variables&quot;, ylab = &quot;BIC&quot;) min.bic &lt;- which.min(smodels$bic) points(nvar[min.bic], smodels$bic[min.bic], pch = 20, col = &quot;red&quot;) abline(h = smodels$bic[min.bic]+2, lty=2) These two plots show that there are many models within 2 of the top model. All the best models have Year and FIP, but there are many different 3rd and 4th variables that can be added and give a similar BIC. Interesting SST does not appear in any of the top models, while it was selected by Stergiou and Christou. This suggests that they computed the yearly SST values slightly differently than I did. My remote sensing data source was slightly different and that might be the cause. 6.3.1.1 Comparison of models chosen by AIC, AICc and BIC step() uses AIC instead of the AICc (corrected for small sample size). In our case, \\(n=23\\) is fairly small and using AICc would be better suited for such a small dataset. leaps does not return AIC or AICc, but we can compute them. Note that Mallow’s Cp asymptotically has the same ordering as AIC, but \\(n=23\\) is small and it does not have the same ordering as AIC in our case. First we use summary() to get a matrix showing the best model of each size. This matrix shows what variable is in the best model of each size. Note that this best model does not depend on the metric (BIC, AIC, etc) because we are looking at models with the same number of variables. The metric affects the penalty for different number of variables and thus only affects the models choice when we compare models of different sizes. models &lt;- leaps::regsubsets(anchovy~., data = df, nvmax = 11, nbest=1, method = &quot;exhaustive&quot;) smodels &lt;- summary(models) head(smodels$which[,1:10]) ## (Intercept) Year Trachurus air slp sst vwnd wspd3 BOP FIP ## 1 TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 2 TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE ## 3 TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE ## 4 TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE TRUE ## 5 TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE FALSE TRUE ## 6 TRUE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE TRUE Next we compute AIC and AICc from BIC. k is the number of parameters. We need to add one more parameter for the estimated variance. k &lt;- apply(smodels$which,1,sum)+1 mod.aicc &lt;- smodels$bic+k*(2+(2*k+2)/(23-k-1))-log(23)*k mod.aic &lt;- smodels$bic+k*2-log(23)*k Now we will plot the metrics for each model size. BIC, AICc and Mallow’s Cp all chose models with an intercept and 3 variables: Year, Trachurus and FIP. AIC selects a much larger model, however with \\(n=23\\), AICc would be a better choice. To find the best model, find the row of the smodels matrix where AICc is the smallest. For example, here is the best model with AICc. rmin &lt;- which(mod.aicc==min(mod.aicc)) colnames(smodels$which)[smodels$which[rmin,]] ## [1] &quot;(Intercept)&quot; &quot;Year&quot; &quot;Trachurus&quot; &quot;FIP&quot; In comparison, the best model with AIC is larger. rmin &lt;- which(mod.aic==min(mod.aic)) colnames(smodels$which)[smodels$which[rmin,]] ## [1] &quot;(Intercept)&quot; &quot;Year&quot; &quot;air&quot; &quot;vwnd&quot; &quot;BOP&quot; ## [6] &quot;FIP&quot; &quot;TOP&quot; olsrr package The olsrr package provides a variety of tools for multivariate regression models, including functions for variable selection. The olsrr functions include nice table and plot outputs. The functions are a bit more user friendly and the package include very clear vignettes that illustrate the functions. The package includes functions for all subsets, forward and backward selection with a variety of different selection metrics. Here is an example of one of the functions. This is for all subsets selection. ols_step_best_subset(full) mindex n predictors rsquare adjr predrsq cp aic sbic sbc msep fpe apc hsp 1 1 Year 0.826 0.818 0.79&nbsp; 16.5&nbsp; -6.63 -73.6 -3.22 0.0406 0.0403 0.207 0.00185 2 2 Year FIP 0.887 0.876 0.846 6.01 -14.6&nbsp; -79.9 -10.1&nbsp; 0.0291 0.0285 0.147 0.00133 3 3 Year Trachurus FIP 0.911 0.897 0.865 3.1&nbsp; -18.1&nbsp; -81.4 -12.5&nbsp; 0.0254 0.0245 0.126 0.00116 4 4 Year Trachurus air FIP 0.921 0.903 0.853 3.21 -18.7&nbsp; -80.1 -11.9&nbsp; 0.0254 0.024&nbsp; 0.124 0.00116 5 5 Year Trachurus air vwnd FIP 0.927 0.905 0.837 3.96 -18.5&nbsp; -77.9 -10.6&nbsp; 0.0264 0.0243 0.125 0.0012&nbsp; 6 6 Year air vwnd BOP FIP TOP 0.936 0.912 0.828 4.06 -19.6&nbsp; -75.4 -10.5&nbsp; 0.0261 0.0233 0.12&nbsp; 0.00119 7 7 Year air slp vwnd BOP FIP TOP 0.94&nbsp; 0.912 0.824 5.25 -19.1&nbsp; -71.9 -8.88 0.028&nbsp; 0.0241 0.124 0.00128 8 8 Year air vwnd wspd3 BOP FIP HPP TOP 0.943 0.911 0.798 6.57 -18.4&nbsp; -67.9 -7.07 0.0305 0.0252 0.13&nbsp; 0.00139 9 9 Year air sst vwnd wspd3 BOP FIP HPP TOP 0.945 0.907 0.782 8.22 -17.1&nbsp; -63.6 -4.64 0.0345 0.0271 0.14&nbsp; 0.00158 10 10 Year air slp sst vwnd wspd3 BOP FIP HPP TOP 0.946 0.901 0.768 10.1&nbsp; -15.5&nbsp; -59.3 -1.85 0.0402 0.0298 0.154 0.00183 11 11 Year Trachurus air slp sst vwnd wspd3 BOP FIP HPP TOP 0.946 0.892 0.732 12&nbsp;&nbsp;&nbsp; -13.6&nbsp; -55&nbsp;&nbsp; 1.18 0.048&nbsp; 0.0333 0.172 0.00219 6.3.2 Model selection with cross-validation6 Variable selection (forward, backward, stepwise) is known to overfit models and variables will be chosen that just happen to have high correlation with your response variable for your particular dataset. The result is models with low out-of-sample predictive accuracy. Cross-validation is a way to try to deal with that problem. Model selection with cross-validation estimates the out-of-sample predictive performance of a process for building a model. So for example, you could use cross-validation to ask the question, “If I select a best model with AIC does that approach led to models with better predictive performance over selecting a best model with BIC?”. The basic idea behind cross-validation is that part of the data is used for fitting (training) the model and the left-out data is used for assessing predictions. You predict the left-out data and compare the actual data to the predictions. There are two common types of cross-validation: leave-one-out cross-validation (LOOCV) and k-fold cross-validation. Leave-one-out cross-validation (LOOCV) is a cross-validation where you leave one data point out, fit to the rest of the data, predict the left out data point, and compute the prediction error with prediction minus actual data value. This is repeated for all data points. So you will have \\(n\\) prediction errors if you have \\(n\\) data points. From these errors, you can compute various statistics. Root mean squared error (RMSE), mean squared error (MSE), and mean absolute error (MAE) are common. k-fold cross-validation is a cross-validation where you divide the data into k equal fractions. The model is fit k times: each fraction is treated as a test data set and the other k-1 fractions are used as the training data. When the model is fit, you predict the data in the test data and compute the prediction errors. Then you’ll compute the statistics (RMSE, MSE, etc) from the errors from all k training sets. There are many different ways you can split your data into k fractions. Thus one often repeats this process many times and uses the average. This is called repeated cross-validation. Example code Let’s see an example of this using models fit via stepwise variable selection using leaps::regsubsets(). Let’s start by defining a predict function for regsubsets objects7. predict.regsubsets &lt;- function(object, newdata, id, ...) { form &lt;- as.formula(object$call[[2]]) mat &lt;- model.matrix(form, newdata) coefi &lt;- leaps:::coef.regsubsets(object, id = id) mat[, names(coefi)] %*% coefi } Next we set up a matrix that defines the folds. Each row has numbers 1 to k (folds) which specify which data points are in the test set. The other (non-k) data points will be the training set. Each row of folds is a different replicate of the repeated cross-validation. nfolds &lt;- 5 nreps &lt;- 20 folds &lt;- matrix(NA, nreps, nrow(df)) for(i in 1:nreps) folds[i,] &lt;- sample(rep(1:nfolds, length = nrow(df))) Now we can use df[folds[r,]==k] to specify the test data for the k-th fold of the r-th replicate. And df[folds[r,]!=k] is the training dataset for the k-th fold of the r-th replicate. The fold jargon is just another word for group. We divide the data into k groups and we call each group a fold. Next we set up a matrix to hold the prediction errors. We will have prediction errors for each fold, each replicate, and each variable (columns). nvmax &lt;- 8 cv.errors &lt;- matrix(0, nreps*nfolds, nvmax) Now, we step through each replicate and each fold in each replicate. We find the best fit with regsubsets() applied to the training set for that replicate. Then we predict using that best fit to the test data for that replicate. We compute the errors (prediction minus data) and store. When we are done, we compute the RMSE (or whatever metric we want). for(r in 1:nreps){ for (k in 1:nfolds) { traindat &lt;- df[folds[r,]!=k,] testdat &lt;- df[folds[r,]==k,] best.fit &lt;- leaps::regsubsets(anchovy ~ ., data=traindat, nvmax = nvmax, method = &quot;seqrep&quot;) for (i in 1:nvmax) { pred &lt;- predict.regsubsets(best.fit, testdat, id = i) cv.errors[r+(k-1)*nreps, i] &lt;- mean((testdat$anchovy - pred)^2) } } } rmse.cv &lt;- sqrt(apply(cv.errors, 2, mean, na.rm=TRUE)) plot(1:nvmax, rmse.cv, pch = 19, type = &quot;b&quot;,xlab=&quot;Number of Variables&quot;, ylab=&quot;RMSE&quot;) The model size with the best predictive performance is smaller, intercept plus 2 variables instead of intercept plus 3 variables. This suggests that we should constrain our model size to 2 variables (plus intercept). Note, that with a 5-fold cross-validation, we were fitting the models to 19 data points instead of 23. However, even with a 23-fold cross-validation (Leave One Out CV), a model with 2 variables has the lowest RMSE. The best fit 2 variable model has Year and FIP. best.fit &lt;- leaps::regsubsets(anchovy ~ ., data=traindat, nvmax = 2, method = &quot;seqrep&quot;) tmp &lt;- summary(best.fit)$which colnames(tmp)[tmp[2,]] ## [1] &quot;(Intercept)&quot; &quot;Year&quot; &quot;FIP&quot; Cross-validation with caret package The the train() function in the caret package allows us to fit and cross-validate model sets easily. trainControl specifies the type of cross-validation and tuneGrid specifies the parameter over which cross-validation will be done (in this case the size of the model). library(caret) # Set up repeated k-fold cross-validation train.control &lt;- trainControl(method = &quot;repeatedcv&quot;, number=5, repeats=20) # Train the model step.model &lt;- train(anchovy~., data = df, method = &quot;leapSeq&quot;, tuneGrid = data.frame(nvmax = 1:nvmax), trControl = train.control ) plot(step.model$results$RMSE, pch = 19, type = &quot;b&quot;, ylab=&quot;RMSE&quot;) The $results part of the output shows us the cross-validation metrics. Best depends on the metric we use. A 2-parameter model is best for all the error metrics except R-squared. step.model$results (#tab:caret.results) nvmaxRMSERsquaredMAERMSESDRsquaredSDMAESD 10.1990.8570.17&nbsp;0.06740.122&nbsp;0.0611 20.1860.8750.1630.04920.09890.0477 30.1990.8230.1640.05460.164&nbsp;0.0495 40.2120.8040.1740.05870.178&nbsp;0.0552 50.2230.7790.1830.05510.188&nbsp;0.0531 60.2160.7820.1780.06550.183&nbsp;0.0589 70.2150.7770.1780.063&nbsp;0.206&nbsp;0.0563 80.2270.7670.1930.06120.208&nbsp;0.0572 The best 2-parameter model has Year and FIP. coef(step.model$finalModel, id=2) ## (Intercept) Year FIP ## -0.01122016 0.07297605 1.04079295 Model selection essentials in R↩︎ James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. An Introduction to Statistical Learning: With Applications in R. Springer Publishing Company, Incorporated.↩︎ Harrell, Frank. 2015. Regression modeling strategies. Springer.↩︎ Raftery, A. E. 1995. Bayesian model selection in social research. Sociological Methodology, 25, 111-163.↩︎ This section and the R code was adapted from and influenced by Chapter 6 material in Introduction to Statistical Learning by James, Witten, Hastie and Tibshirani. They have an online course and (free) textbook at http://www-bcf.usc.edu/~gareth/ISL/ .↩︎ This section and the R code was adapted from and influenced by Chapter 6 material in Introduction to Statistical Learning by James, Witten, Hastie and Tibshirani. They have an online course and (free) textbook at http://www-bcf.usc.edu/~gareth/ISL/ .↩︎ This function was copied from the Introduction to Statistical Learning material.↩︎ "],
["6-4-MREGPR.html", "6.4 Penalized regression", " 6.4 Penalized regression The problem with model selection using searching and selecting with some model fit criteria is that the selected model tends to be over-fit—even when using cross-validation. The predictive value of the model is not optimal because of over-fitting. Another approach to dealing with variance inflation that arises from collinearity and models with many explanatory variable is penalized regression. The basic idea with penalized regression is that you penalize coefficient estimates that are far from 0. The true coefficients are (likely) not 0 so fundamentally this will lead to biased coefficient estimates but the idea is that the inflated variance of the coefficient estimates is the bigger problem. 6.4.1 Ridge Regression First, let’s look at ridge regression. With ridge regression, we will assume that the coefficients have a mean of 0 and a variance of \\(1/\\lambda\\). This is our prior on the coefficients. The \\(\\beta_i\\) are the most probable values given the data and the prior. Note, there are many other ways to derive ridge regression. We will use the glmnet package to fit the anchovy catch with ridge regression. To fit with a ridge penalty, we set alpha=0. library(glmnet) resp &lt;- colnames(dfz)!=&quot;anchovy&quot; x &lt;- as.matrix(dfz[,resp]) y &lt;- as.matrix(dfz[,&quot;anchovy&quot;]) fit.ridge &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=0) We need to choose a value for the penalty parameter \\(\\lambda\\) (called s in coef.glmnet()). If \\(\\lambda\\) is large, then our prior is that the coefficients are very close to 0. If our \\(\\lambda\\) is small, then our prior is less informative. We can use cross-validation to choose \\(\\lambda\\). This chooses a \\(\\lambda\\) that gives us the lowest out of sample errors. cv.glmnet() will do k-fold cross-validation and report the MSE. We pick the \\(\\lambda\\) with the lowest MSE (lambda.min) or the largest value of \\(\\lambda\\) such that error is within 1 s.e. of the minimum (lambda.1se). This value is computed via cross-validation so will vary. We will take the average over a number of runs; here 20 for speed but 100 is better. Once we have a best \\(\\lambda\\) to use, we can get the coefficients at that value. n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=0)$lambda.min s.best.ridge &lt;- s/n coef(fit.ridge, s=s.best.ridge) ## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 ## (Intercept) -1.025097e-14 ## Year 5.417884e-01 ## Trachurus -1.828772e-01 ## air 1.897000e-01 ## slp -8.056669e-02 ## sst -8.958912e-02 ## vwnd 8.140451e-02 ## wspd3 2.616673e-02 ## BOP 9.399500e-02 ## FIP 1.156512e-01 ## HPP 3.036030e-01 ## TOP 2.358358e-01 I will plot the standardized coefficients for the ordinary least squares coefficients against the coefficients using ridge regression. This shows the problem caused by the highly collinear TOP and HPP. They have highly inflated coefficient estimates that are offset by an inflated Year coefficient (in the opposite direction). This is why we need to evaluate collinearity in our variables before fitting a linear regression. With ridge regression, all the estimates have shrunk towards 0 (as they should) but the collinear variables still have very large coefficients. 6.4.2 Lasso In ridge regression, the coefficients will be shrunk towards 0 but none will be set to 0 (unless the OLS estimate happens to be 0). Lasso is a type of regression that uses a penalty function where 0 is an option. Lasso does a combination of variable selection and shrinkage. We can do lasso with glmnet() by setting alpha=1. fit.lasso &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=1) We select the best \\(\\lambda\\) as we did for ridge regression using cross-validation. n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=1)$lambda.min s.best.lasso &lt;- s/n coef.lasso &lt;- as.vector(coef(fit.lasso, s=s.best.lasso))[-1] We can compare to the estimates from ridge and OLS and see that the model is now more similar the models we got from stepwise variable selection. The main difference is that slp and air are included as variables. Lasso has estimated a model that is similar to what we got with stepwise variable selection without removing the collinear variables from our data set. 6.4.3 Elastic net Elastic net is uses both L1 and L2 regularization. Elastic regression generally works well when we have a big dataset. We do not have a big dataset but we will try elastic net. You can tune the amount of L1 and L2 mixing by adjusting alpha but for this example, we will just use alpha=0.5. fit.en &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=0.5) n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=0.5)$lambda.min s.best.el &lt;- s/n coef.en &lt;- as.vector(coef(fit.en, s=s.best.el))[-1] As we might expect, elastic net is part way between the ridge regression model and the Lasso model. "],
["6-5-MREGRELPO.html", "6.5 Relative importance metrics", " 6.5 Relative importance metrics Another approach to linear regression with multiple collinear regressors is to compute relative importance metrics8. The relaimpo package will compute the relative importance metrics and provides plotting. This gives a somewhat different picture with year, Trachurus and the effort metrics most important while the environmental variables have low importance. reli &lt;- relaimpo::calc.relimp(anchovy~.,data=df) plot(reli) The pattern remains the same without Year as a response variable. reli &lt;- relaimpo::calc.relimp(anchovy~.-Year,data=df) plot(reli) Groemping, U. (2006) Relative Importance for Linear Regression in R: The Package relaimpo Journal of Statistical Software 17, Issue 1. Downloadable at http://www.jstatsoft.org/v17/i01↩︎ "],
["6-6-MREGORTHO.html", "6.6 Orthogonalization", " 6.6 Orthogonalization The last approach that we will discuss for dealing with collinearity is orthogonalization. With this technique, we replace the set of collinear covariates \\(X\\) with a set of orthogonal, i.e. independent, covariates \\(Z\\), which are linear combinations of the original, collinear, covariates. Principal Components Analysis (PCA) is an example of using orthogonalization to deal with collinear covariates. Another example is when we use the poly() function to do polynomial regression. In this case, we are replacing a set of collinear variates, \\(x\\), \\(x^2\\), \\(x^3\\), etc., with a set of orthogonal covariates. The ways that you can create a set of orthogonal covariates is not unique. There are many different sets of orthogonal covariates. We will show three ways you might create your orthogonal set: PCA, Gram-Schmidt Orthogonalization, and residuals from linear regressions. Note, it is important to use standardized covariates with the mean removed and variance scaled to 1 when doing orthogonalization. Thus we will use dfz instead of df. 6.6.0.1 Principal component regression Principal component regression is a linear regression in which you transform your collinear covariates using the othogonal variates created by Principal Components Analysis (PCA). PCA uses an orthogonal set of variates \\(Z\\) in which the first variate accounts for as much of the variability in the variate dataset as possible, the second accounts for as much of the remaining variance as possible, the third accounts for as much of the variance remaining after the first two, etc., etc. Each variate is orthogonal to the preceding variate. Singular value decomposition is a standard way to compute \\(Z\\) for PCA. \\[Z = XV\\] where \\(V\\) is the right singular vector from the singular value decomposition of the matrix of covariates (\\(X=UDV&#39;\\)). The \\(V\\) is the ‘loadings’ matrix in a PCA. The orthogonal covariates \\(Z\\) are linear combinations of the original, collinear, covariates. PCA covariates have the nice feature that they are ordered in terms of the amount of variance they explain, but the orthogonal variates, called axes in a PCA, can be a bit hard to interpret. Let’s see an example with our data set. First we will create a matrix of our collinear variates. We need to use the scaled variates. X &lt;- as.matrix(dfz[,colnames(dfz)!=&quot;anchovy&quot;]) We create our orthogonal PCA variates using the svd() function which does a singular value decomposition. We will re-label the variates as ‘principal components (PC)’. A corrplot shows that our variates are now uncorrelated. loadings &lt;- svd(X)$v rownames(loadings) &lt;- colnames(X) Z &lt;- X%*%loadings colnames(Z) &lt;- paste0(&quot;PC&quot;, 1:ncol(Z)) corrplot(cor(Z)) These new variates are linear combinations of the original variates. The “loadings” indicate the weight of each original variate in the new variate (“principal component”). library(reshape2) meltR = melt(loadings) ggplot(meltR, aes(x=Var1, y = value)) + geom_bar(stat=&quot;identity&quot;) + coord_flip() + facet_wrap(. ~ Var2) + ggtitle(&quot;Loadings&quot;) The \\(Z\\) matrix gives us a set of orthogonal variates, but some of them do not explain much of the variance. We know this should be the case because we have collinearity in our data. The singular values (which are square root of the eigenvalues of \\(X^\\top X\\)) show how much of the variance in \\(X\\) explained by each pricipal component (column in \\(Z\\)). In the plot, the singular values were of \\(X/\\sqrt{n}\\) so that \\(X^\\top X\\) is the correlation matrix. The average singular value for a correlation matrix is 1. With this scaling, any singlular value much less than one is small. sing.val &lt;- svd(X/sqrt(n))$d plot(sing.val, xlab=&quot;axis&quot;, ylab=&quot;singular value&quot;) abline(h=1, col=&quot;red&quot;) We could run a linear regression with all the 11 orthogonal variates (principal components), but that would not be helpful. The point of orthogonalization is to find a smaller set of variates that explains the structure in the larger set of collinear variates. Based on the singular value plot, we will use the first 2 components. These 2 capture a fair bit of the variability in the anchovy catch. dfpca &lt;- data.frame(anchovy=dfz$anchovy, Z[,1:2]) pcalm &lt;- lm(anchovy ~ ., data=dfpca) summary(pcalm) ## ## Call: ## lm(formula = anchovy ~ ., data = dfpca) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0413 -0.4149 0.1160 0.4328 0.8402 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.209e-15 1.166e-01 0.000 1.00000 ## PC1 3.405e-01 5.090e-02 6.688 1.65e-06 *** ## PC2 -2.278e-01 7.671e-02 -2.970 0.00757 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5592 on 20 degrees of freedom ## Multiple R-squared: 0.7281,\tAdjusted R-squared: 0.7009 ## F-statistic: 26.78 on 2 and 20 DF, p-value: 2.209e-06 We can also plot the anchovy catch, broken into small, medium, and large, against the 2 components and see that the 2 components do separate these broad catch levels. library(ggplot2) library(grid) library(gridExtra) df_pca &lt;- prcomp(X) df_out &lt;- as.data.frame(df_pca$x) df_out$group &lt;- cut(dfz$anchovy,3) p&lt;-ggplot(df_out,aes(x=PC1,y=PC2,color=group )) p&lt;-p+geom_point() p We can recover the effect sizes for the original variates from \\(V\\tilde{\\beta}\\). This gives a similar picture as the other methods we used. Year, TOP/HPP/BOP and Trachurus come out as important. coef(pcalm) ## (Intercept) PC1 PC2 ## 6.209379e-15 3.404684e-01 -2.278441e-01 eff &lt;- data.frame(value=svd(X)$v[,1:2] %*% coef(pcalm)[-1], var=colnames(X)) ggplot(eff, aes(x=var, y = value)) + geom_bar(stat=&quot;identity&quot;) + coord_flip() + ggtitle(&quot;Effects on scaled original vars&quot;) Principal Components Regression (PCR) is a method for dimension reduction, like Lasso regression or variable selection, but your new principal components can be hard to interpret because they are linear combinations of the original variates. In addition, if you are trying to understand if a particular variate improves your model, then PCR is going to help you. Another approach for creating orthogonal variates is Gram-Schmidt orthogalization and this can help study the effect of adding specific variates. 6.6.0.2 Gram-Schmidt Orthogonalization The Gram-Schmidt orthogonalization treats the variates in a specific order. The first orthogonal variate will be the first variate, the second othogonal variate will be the variation in the second variate that is not explained by the first, the third will be the variation in the third variate that is not explained by the first two, etc. This makes your orthogonal variates easier to interpret if they have some natural or desired ordering. For example, let’s say we want to study if adding TOP to our model help explain variance over what is already explained by Year. Putting both TOP and Year in a model won’t be helpful because they are highly correlated and we’ll just get effect sizes that offset each other (one negative, one positive) with high standard errors. Instead, we’ll add Year and then add a second variate that is the variability in TOP that is not explained by Year. Why not add TOP first? The ordering is up to you and depends on the specific question you are asking. In this case, we asking what TOP adds to a model with Year not what Year adds to a model with TOP. We create the Let \\(Z\\) be the matrix of orthogonal variates and \\(X\\) be the matrix of original, collinear, covariates. The first column of \\(Z\\) is \\(Z_1 = X_1\\). The second column of \\(Z\\) is \\[Z_2 = X_2 - Z_1(Z_1^\\top Z_1)Z_1^\\top X_2.\\] The third column of \\(Z\\) is \\[Z_3 = X_3 - Z_1(Z_1^\\top Z_1)Z_1^\\top X_3 - Z_2(Z_2^\\top Z_2)Z_2^\\top X_3.\\] Here is R code to create the first 3 columns of the Z matrix. The cross-product of Z is diagonal, indicating that our new variates are orthogonal. pr &lt;- function(y, x){ x%*%solve(t(x)%*%x)%*%t(x)%*%y } Z &lt;- cbind(X[,1], 0, 0) Z[,2] &lt;- X[,2] - pr(X[,2], Z[,1]) Z[,3] &lt;- X[,3] - pr(X[,3], Z[,1]) - pr(X[,3], Z[,2]) zapsmall(crossprod(Z)) ## [,1] [,2] [,3] ## [1,] 23 0.000000 0.0000 ## [2,] 0 6.757089 0.0000 ## [3,] 0 0.000000 22.1069 To create our orthogonal variates, we have to give some thought to the ordering. Also not all the variates in our example are collinear. So we don’t need to do Gram-Schimdt Orthogonalization on all the variates. From the variance inflation factors, Year, HPP, TOP, BOP and Trachusus have the worst collinearity problems. full &lt;- lm(anchovy ~ ., data=df) car::vif(full) ## Year Trachurus air slp sst vwnd wspd3 ## 103.922970 18.140279 3.733963 3.324463 2.476689 2.010485 1.909992 ## BOP FIP HPP TOP ## 13.676208 8.836446 63.507170 125.295727 We’ll do Gram-Schmidt orthogonalization on these 5. First let’s resort our variates to put these 5 first. pr &lt;- function(y, x){ x%*%solve(t(x)%*%x)%*%t(x)%*%y } Z &lt;- X[,c(&quot;Year&quot;,&quot;BOP&quot;,&quot;HPP&quot;,&quot;TOP&quot;,&quot;Trachurus&quot;,&quot;FIP&quot;,&quot;air&quot;,&quot;slp&quot;,&quot;sst&quot;,&quot;vwnd&quot;,&quot;wspd3&quot;)] Z[,2] &lt;- X[,2] - pr(X[,2], Z[,1]) Z[,3] &lt;- X[,3] - pr(X[,3], Z[,1]) - pr(X[,3], Z[,2]) zapsmall(crossprod(Z)) ## Year BOP HPP TOP Trachurus FIP ## Year 23.000000 0.000000 0.000000 21.489875 19.328398 -13.995187 ## BOP 0.000000 6.757089 0.000000 2.743112 6.757089 -0.836240 ## HPP 0.000000 0.000000 22.106900 2.906483 0.000000 7.049420 ## TOP 21.489875 2.743112 2.906483 23.000000 20.802454 -9.247200 ## Trachurus 19.328398 6.757089 0.000000 20.802454 23.000000 -12.597306 ## FIP -13.995187 -0.836240 7.049420 -9.247200 -12.597306 23.000000 ## air -3.834139 -1.309927 22.106900 -1.207694 -4.532004 9.544555 ## slp 12.722819 3.030045 -6.167315 11.179809 13.721858 -12.356850 ## sst -5.105424 -0.381354 14.974748 -1.749126 -4.671774 8.493349 ## vwnd 2.278039 2.424582 -11.802674 3.176227 4.338966 -1.073977 ## wspd3 2.219684 -0.922046 -6.961443 -0.226925 0.943299 -5.505128 ## air slp sst vwnd wspd3 ## Year -3.834139 12.722819 -5.105424 2.278039 2.219684 ## BOP -1.309927 3.030045 -0.381354 2.424582 -0.922046 ## HPP 22.106900 -6.167315 14.974748 -11.802674 -6.961443 ## TOP -1.207694 11.179809 -1.749126 3.176227 -0.226925 ## Trachurus -4.532004 13.721858 -4.671774 4.338966 0.943299 ## FIP 9.544555 -12.356850 8.493349 -1.073977 -5.505128 ## air 23.000000 -8.875634 15.899760 -12.652455 -7.152721 ## slp -8.875634 23.000000 -9.371464 7.341141 -1.298503 ## sst 15.899760 -9.371464 23.000000 -7.755410 -3.926768 ## vwnd -12.652455 7.341141 -7.755410 23.000000 4.991220 ## wspd3 -7.152721 -1.298503 -3.926768 4.991220 23.000000 "],
["6-7-MREGPREDICT.html", "6.7 Prediction accuracy", " 6.7 Prediction accuracy We could use cross-validation compare prediction accuracy if we had a pre-defined set of models to compare. In our case, we do not have a set of models but rather a set of “number of variables” and the specific variables to include in that number are determined using the fit to the data (in some fashion). We cannot use variable selection (any sort) with our full dataset to chose the variables and then turn around and use cross-validation with the same dataset to test the out-of-sample prediction accuracy. Anytime you double-use your data like that, you will have severe bias problems. Instead, we will test our models using sets of years that we held out for testing, i.e. that were not used for fitting the model or selecting variates. We will use the following test years: 1988 and 1989 as was used in Stergiou and Christou and 1988-1992 (five years). We will use the performance testing procedure in Chapter 5. Computing the prediction error for a model First we set up the test data frames. We can then compute the RMSE for the predictions from one of our linear regression models. Let’s use the model selected by step() using AIC as the metric and stepwise variable regression starting from a full model, step.full. fr &lt;- predict(step.full, newdata=testdata2) err &lt;- fr - testdata2$anchovy sqrt(mean(err^2)) ## [1] 0.05289656 We could also use forecast() in the forecast package to compute predictions and then use accuracy() to compute the prediction metrics for the test data. fr &lt;- forecast::forecast(step.full, newdata=testdata2) forecast::accuracy(fr, testdata2) ## ME RMSE MAE MPE MAPE MASE ## Training set 0.00000000 0.11151614 0.08960780 -0.01540787 0.9925324 0.2480860 ## Test set -0.03755081 0.05289656 0.03755081 -0.39104145 0.3910415 0.1039623 Comparing the predictions for a suite of models Let’s compare a suite of models and compare predictions for the full out-of-sample data that we have: 1988 to 2007. fr.list &lt;- list() testdat &lt;- testdata.full &lt;- df.full[24:nrow(df.full),] n.fr &lt;- length(testdat) Then we fit the three best lm models chosen via stepwise regression, exhaustive search or cross-validation: modelname &lt;- &quot;Year+FIP&quot; fit &lt;- lm(anchovy~Year+FIP, data=df) fr.list[[modelname]] &lt;- predict(fit, newdata=testdat) modelname &lt;- &quot;Year+Trachurus+FIP&quot; fit &lt;- lm(anchovy~Year+Trachurus+FIP, data=df) fr.list[[modelname]] &lt;- predict(fit, newdata=testdat) modelname &lt;- &quot;6 variables&quot; fit &lt;- lm(anchovy~Year+air+vwnd+BOP+FIP+TOP, data=df) fr.list[[modelname]] &lt;- predict(fit, newdata=testdat) Then we add the forecasts for Ridge Regression. library(glmnet) resp &lt;- colnames(df)!=&quot;anchovy&quot; x &lt;- as.matrix(df[,resp]) y &lt;- as.matrix(df[,&quot;anchovy&quot;]) fit &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=0) n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=0)$lambda.min s.best &lt;- s/n modelname &lt;- &quot;Ridge Regression&quot; newx &lt;- as.matrix(testdat[,resp]) fr.list[[modelname]] &lt;- predict(fit, newx=newx, s=s.best) LASSO regression, fit &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=1) n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=1)$lambda.min s.best &lt;- s/n modelname &lt;- &quot;LASSO Regression&quot; newx &lt;- as.matrix(testdat[,resp]) fr.list[[modelname]] &lt;- predict(fit, newx=newx, s=s.best) and elastic net regression. fit &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=0.5) n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=0.5)$lambda.min s.best &lt;- s/n modelname &lt;- &quot;Elastic net Regression&quot; newx &lt;- as.matrix(testdat[,resp]) fr.list[[modelname]] &lt;- predict(fit, newx=newx, s=s.best) Now we can create a table restab &lt;- as.data.frame(matrix(NA,1,21)) #restab &lt;- data.frame(model=&quot;&quot;, stringsAsFactors=FALSE) for(i in 1:length(fr.list)){ err &lt;- fr.list[[i]]-testdat$anchovy restab[i,2:(length(err)+1)] &lt;- sqrt(cumsum(err^2)/1:length(err)) restab[i,1] &lt;- names(fr.list)[i] } tmp &lt;- restab[,c(1,6,11,16,21)] colnames(tmp) &lt;- c(&quot;model&quot;,&quot;5 yrs&quot;, &quot;10 yrs&quot;, &quot;15 yrs&quot;, &quot;20 yrs&quot;) knitr::kable(tmp) model 5 yrs 10 yrs 15 yrs 20 yrs Year+FIP 0.6905211 0.8252467 0.9733136 1.0597621 Year+Trachurus+FIP 0.8324962 0.9598570 1.2391294 1.4442466 6 variables 0.3612936 0.6716181 0.9543952 1.1356324 Ridge Regression 0.7822712 0.8393271 0.9564713 0.9673194 LASSO Regression 0.5959503 0.7471635 1.0132615 1.1769412 Elastic net Regression 0.7092379 0.8589573 1.1609910 1.3481830 If we plot the forecasts with the 1965-1987 data (open circles) and the 1988-2007 data (solid circles), we see that the forecasts continue the upward trend in the data while the data level off. This illustrates a problem with using “Year” as a covariate. This covariate is deterministically increasing. If it is included in the model, then the forecasts will have an upward or downward trend. When using environmental, biological and effort covariates, one hopes that the covariates explain the trends in the data. It would be wiser to not use “Year” as a covariate. LASSO regression with no year, resp &lt;- colnames(df)!=&quot;anchovy&quot; &amp; colnames(df)!=&quot;Year&quot; x &lt;- as.matrix(df[,resp]) y &lt;- as.matrix(df[,&quot;anchovy&quot;]) fit.lasso &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=1) n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=1)$lambda.min s.best.lasso &lt;- s/n modelname &lt;- &quot;LASSO Reg no Year&quot; newx &lt;- as.matrix(testdat[,resp]) fr.list[[modelname]] &lt;- predict(fit.lasso, newx=newx, s=s.best.lasso) Ridge regression with no year, resp &lt;- colnames(df)!=&quot;anchovy&quot; &amp; colnames(df)!=&quot;Year&quot; x &lt;- as.matrix(df[,resp]) y &lt;- as.matrix(df[,&quot;anchovy&quot;]) fit.ridge &lt;- glmnet(x, y, family=&quot;gaussian&quot;, alpha=0) n &lt;- 20; s &lt;- 0 for(i in 1:n) s &lt;- s + cv.glmnet(x, y, nfolds=5, alpha=1)$lambda.min s.best.ridge &lt;- s/n modelname &lt;- &quot;Ridge Reg no Year&quot; newx &lt;- as.matrix(testdat[,resp]) fr.list[[modelname]] &lt;- predict(fit.ridge, newx=newx, s=s.best.ridge) Now we can create a table model 5 yrs 10 yrs 15 yrs 20 yrs 7 LASSO Reg no Year 0.7277462 0.7200965 0.7306603 0.6668768 8 Ridge Reg no Year 0.9741012 0.9555257 0.9792060 0.9121324 Without “Year”, the model predicts 1988 well (using 1987 covariates) but then has a large jump upward after which is has a similar “flat-ish” trend as seen after 1989. What happened in 1988 (the covariate year affecting 1989)? The horsepower covariate, along with BOP (total boats) and TOP (boat tonnage), have a sudden upward jump in 1988. This is seen in all the fisheries. This suggests that in 1988 either a large number of new boats entered all the fisheries or what boats were counted as “purse seiners” was changed. Upon looking at the covariates, it seems that something changed in the recording from 1988 to 1996. If we correct that jump from 1988 to 1989 (subtract the jump from all data 1989 onward), the Lasso and Ridge predictions without year look considerably better. "],
["6-8-discussion.html", "6.8 Discussion", " 6.8 Discussion This chapter illustrates a variety of approaches for “variable selection”. This is the situation where one has a large number of covariates and one wants to chose the covariates that produce the best predictions. Following Stergiou and Christou, I used mainly linear regressions with variables selected with stepwise variable selection. Keep in mind that stepwise variable selection is generally considered data-dredging and a reviewer who is statistician will almost certainly find fault with this approach. Penalized regression is a more accepted approach for developing a regression model with many covariates. Part of the appeal of penalized regression is that it is robust to collinearity in your covariates. Stepwise variable regression is not robust to collinearity. Cross-validation is an approach for testing a process of building a model. In the case of the anchovy data, a model with only two covariates, Year and number of fishers, was selected via cross-validation as having the best (lowest) predictive error. This is considerable smaller than the best model via stepwise variable selection. When we tested the models against data completely held out of the analysis and model development (1988-2007), we discovered a number of problems. 1) Using “Year” as a covariate is a bad idea since it is deterministically linear upward. and 2) There is a problem with the effort data between 1988 and 1996. There is a jump in the effort data. We used variable selection or penalized regression to select weighting on a large set of covariates. Another approach is to develop a set of covariates from your knowledge of the system and use only covariates that are thought to be important. In Section 4.7.7 of (Harrell 2015), a rule of thumb (based on shrinkage) for the number of predictors that can be used without overfitting is given by: \\((LR-p)/9\\) where \\(LR\\) is the likelihood ratio test \\(\\chi^2\\) of the full model against the null model with only intercept and \\(p\\) is the number of variables in the full model. null &lt;- lm(anchovy ~ 1, data=df) full &lt;- lm(anchovy ~ ., data=df) a &lt;- lmtest::lrtest(null, full) (a$Chisq[2]-a$Df[2])/9 ## [1] 6.239126 This rule of thumb suggests that we could include six variables. Another approach to model building would be to select environmental and biological variables based on the known biology of anchovy and to select one effort variable or a composite “effort” based on a combination of the effort variables. "],
["7-ar-models-with-covariates.html", "Chapter 7 AR models with covariates", " Chapter 7 AR models with covariates "],
["7-1-MREGARMA.html", "7.1 MREG with ARMA errors", " 7.1 MREG with ARMA errors library(ggplot2) library(forecast) library(astsa) library(nlme) The stats::arima() and forecast::auto.arima() functions with argument xreg fit a multivariate linear regression with ARMA errors. Note, this is not what is termed a ARMAX model. ARMAX models will be addressed in Section 7.2. The model fitted when xreg is passed in is: \\[\\begin{equation} \\begin{gathered} x_t = \\alpha + \\phi_1 c_{t,1} + \\phi_2 c_{t,2} + \\dots + z_t \\\\ z_t = \\beta_1 z_{t-1} + \\dots + \\beta_p z_{t-p} + e_t + \\theta_1 e_{t-1} + \\dots + \\theta_q e_{t-q}\\\\ e_t \\sim N(0,\\sigma) \\end{gathered} \\end{equation}\\] where xreg is matrix with \\(c_{t,1}\\) in column 1, \\(c_{t-2}\\) in column 2, etc. \\(z_t\\) are the ARMA errors. 7.1.1 Example: fitting with auto.arima Let’s fit two of the best multivariate regression models from Section 6.3.1 with ARMA errors. We can use auto.arima to search for an ARMA model for the residuals. xreg &lt;- as.matrix(df[,c(&quot;Year&quot;,&quot;FIP&quot;)]) forecast::auto.arima(df$anchovy, xreg=xreg) ## Series: df$anchovy ## Regression with ARIMA(0,0,0) errors ## ## Coefficients: ## Year FIP ## 0.0730 1.0394 ## s.e. 0.0046 0.0079 ## ## sigma^2 estimated as 0.024: log likelihood=11.3 ## AIC=-16.6 AICc=-15.34 BIC=-13.2 The esimated model is a “Regression with ARIMA(0,0,0) errors” which indicates no autoregressive or moving average pattern in the residuals. We can also see this by looking at an ACF plot of the residuals. lm(anchovy~Year+FIP,data=df) %&gt;% resid %&gt;% acf The same pattern is seen with the models with more variables. xreg &lt;- as.matrix(df[,c(&quot;Year&quot;,&quot;Trachurus&quot;,&quot;FIP&quot;)]) forecast::auto.arima(df$anchovy, xreg=xreg) ## Series: df$anchovy ## Regression with ARIMA(0,0,0) errors ## ## Coefficients: ## Year Trachurus FIP ## 0.0883 -0.2339 1.2686 ## s.e. 0.0083 0.1092 0.1073 ## ## sigma^2 estimated as 0.02101: log likelihood=13.39 ## AIC=-18.78 AICc=-16.56 BIC=-14.24 7.1.2 Example: fitting with arima and sarima If we want to fit a specific ARMA model, for example an AR(1) model for the residuals, we can use arima. xreg &lt;- as.matrix(df[,c(&quot;Year&quot;,&quot;FIP&quot;)]) arima(df$anchovy, xreg=xreg, order = c(1,0,0)) ## ## Call: ## arima(x = df$anchovy, order = c(1, 0, 0), xreg = xreg) ## ## Coefficients: ## ar1 intercept Year FIP ## -0.0404 -0.0975 0.0729 1.0517 ## s.e. 0.2256 2.3540 0.0057 0.2920 ## ## sigma^2 estimated as 0.02188: log likelihood = 11.32, aic = -12.64 We can also use the sarima function in the astsa package. This plots a nice diagnostics plot with the fit. xreg &lt;- as.matrix(df[,c(&quot;Year&quot;,&quot;FIP&quot;)]) astsa::sarima(df$anchovy, 1, 0, 0, xreg=xreg) ## initial value -1.932551 ## iter 2 value -1.945583 ## iter 3 value -1.946840 ## iter 4 value -1.946961 ## iter 5 value -1.946974 ## iter 6 value -1.946976 ## iter 7 value -1.946976 ## iter 7 value -1.946976 ## iter 7 value -1.946976 ## final value -1.946976 ## converged ## initial value -1.897686 ## iter 2 value -1.910866 ## iter 3 value -1.910989 ## iter 4 value -1.911001 ## iter 5 value -1.911004 ## iter 5 value -1.911004 ## iter 5 value -1.911004 ## final value -1.911004 ## converged ## $fit ## ## Call: ## stats::arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, ## Q), period = S), xreg = xreg, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, ## REPORT = 1, reltol = tol)) ## ## Coefficients: ## ar1 intercept Year FIP ## -0.0404 -0.0975 0.0729 1.0517 ## s.e. 0.2256 2.3540 0.0057 0.2920 ## ## sigma^2 estimated as 0.02188: log likelihood = 11.32, aic = -12.64 ## ## $degrees_of_freedom ## [1] 19 ## ## $ttable ## Estimate SE t.value p.value ## ar1 -0.0404 0.2256 -0.1791 0.8597 ## intercept -0.0975 2.3540 -0.0414 0.9674 ## Year 0.0729 0.0057 12.8250 0.0000 ## FIP 1.0517 0.2920 3.6024 0.0019 ## ## $AIC ## [1] -0.549349 ## ## $AICc ## [1] -0.4527307 ## ## $BIC ## [1] -0.3025025 7.1.3 Example: fitting with gls We can also fit multivariate regression with autocorrelated errors with the nlme package and function gls(). The default fitting method is REML, and to get the same results as arima(), we need to specify method=\"ML\". mod &lt;- gls(anchovy~Year+FIP, data=df, correlation=corAR1(form=~1), method=&quot;ML&quot;) summary(mod) ## Generalized least squares fit by maximum likelihood ## Model: anchovy ~ Year + FIP ## Data: df ## AIC BIC logLik ## -12.63503 -6.957558 11.31751 ## ## Correlation Structure: AR(1) ## Formula: ~1 ## Parameter estimate(s): ## Phi ## -0.04023925 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) -0.0970390 2.4776517 -0.039166 0.9691 ## Year 0.0729497 0.0060939 11.971012 0.0000 ## FIP 1.0516813 0.3070037 3.425630 0.0027 ## ## Correlation: ## (Intr) Year ## Year -0.631 ## FIP -1.000 0.612 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -1.5299235 -0.9188421 0.2607087 0.6691076 2.1482577 ## ## Residual standard error: 0.1480464 ## Degrees of freedom: 23 total; 20 residual You can also fit an AR(2) or ARMA with gls(): mod &lt;- gls(anchovy~Year+FIP, data=df, correlation=corARMA(form = ~1,p=2,q=0), method=&quot;ML&quot;) summary(mod) ## Generalized least squares fit by maximum likelihood ## Model: anchovy ~ Year + FIP ## Data: df ## AIC BIC logLik ## -12.033 -5.220033 12.0165 ## ## Correlation Structure: ARMA(2,0) ## Formula: ~1 ## Parameter estimate(s): ## Phi1 Phi2 ## -0.09861143 -0.28248099 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) -1.1700795 2.0440075 -0.572444 0.5734 ## Year 0.0732924 0.0048706 15.047960 0.0000 ## FIP 1.1869743 0.2533707 4.684734 0.0001 ## ## Correlation: ## (Intr) Year ## Year -0.662 ## FIP -1.000 0.645 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -1.6245159 -0.9492037 0.1640458 0.6481195 2.1941017 ## ## Residual standard error: 0.1494797 ## Degrees of freedom: 23 total; 20 residual 7.1.4 MREG of first or second differences In the multivariate regression with ARMA errors, the response variable \\(x_t\\) is not necessarily stationary since the covariates \\(c_t\\)’s need not be stationary. If we wish to model the first or second differences of \\(x_t\\), then we are potentially modeling a stationary process if differencing leads to a stationary process. We need to think carefully about how we set up a multivariate regression if our response variable is stationary. One recommendation is if \\(x_t\\) is differenced, the same differencing is applied to the covariates. The idea is if the response variable is stationary, we want to make sure that the independent variables are also stationary. However, in a fisheries application \\(x_t - x_{t-1}\\) often has a biological meaning, the yearly (or monthly or hourly) rate of change, and that rate of change is what one is trying explain with a covariate. One would not necessarily expect the first difference to be stationary and one is trying to explain any trend in the one-step rate of change with some set of covariates. On the other hand, if the response variable, the raw data or the first or second difference, is stationary then trying to explain its variability via a non-stationary covariate will clearly lead to the effect size of the covariates being zero. We don’t need to fit a model to tell us that. 7.1.5 Discussion R provides many different functions and packages for fitting a multivariate regression with autoregressive errors. In the case of the anchovy time series, the errors are not autoregressive. In general, the first step to determining whether a model with correlated errors is required is to look at diagnostics for the residuals. Select a model (see previous section) and then examine the residuals for evidence of autocorrelation. However another approach is to include a model with autocorrelated errors in your model set and compare via model selection. If this latter approach is taken, you must be careful to that the model selection criteria (AIC, BIC etc) are comparable. If you use functions from different packages, they authors have often left off a constant in their model selection criteria formulas. If you need to use different packages, you will carefully test the model selection criteria from the same model with different functions and adjust for the missing constants. "],
["7-2-ARMAX.html", "7.2 ARMAX Models", " 7.2 ARMAX Models library(MARSS) The stats::arima() and forecast::auto.arima() functions with argument xreg fit a multivariate linear regression with ARMA errors. Note, this is not what is termed a ARMAX model. ARMAX models will be addressed separately. The model fitted when xreg is passed in is: \\[\\begin{equation} \\begin{gathered} x_t = \\alpha + \\phi_1 c_{t,1} + \\phi_2 c_{t,2} + \\dots + z_t \\\\ z_t = \\beta_1 z_{t-1} + \\dots + \\beta_p z_{t-p} + e_t + \\theta_1 e_{t-1} + \\dots + \\theta_q e_{t-q}\\\\ e_t \\sim N(0,\\sigma) \\end{gathered} \\end{equation}\\] where xreg is matrix with \\(c_{t,1}\\) in column 1, \\(c_{t-2}\\) in column 2, etc. \\(z_t\\) are the ARMA errors. 7.2.1 Discussion R provides many different functions and packages for fitting a multivariate regression with autoregressive errors. In the case of the anchovy time series, the errors are not autoregressive. In general, the first step to determining whether a model with correlated errors is required is to look at diagnostics for the residuals. Select a model (see previous section) and then examine the residuals for evidence of autocorrelation. However another approach is to include a model with autocorrelated errors in your model set and compare via model selection. If this latter approach is taken, you must be careful to that the model selection criteria (AIC, BIC etc) are comparable. If you use functions from different packages, they authors have often left off a constant in their model selection criteria formulas. If you need to use different packages, you will carefully test the model selection criteria from the same model with different functions and adjust for the missing constants. "],
["8-seasonality.html", "Chapter 8 Seasonality", " Chapter 8 Seasonality To work with seasonal data, we need to turn our data into a ts object, which is a “time-series” object in R. This will allow us to specify the seasonality. It is important that we do not leave out any data in our time series. You data should look like so Year Month metric.tons 2018 1 1 2018 2 2 2018 3 3 ... 2019 1 4 2019 2 6 2019 3 NA The months are in order and the years are in order.\n"],
["8-1-chinook-data.html", "8.1 Chinook data", " 8.1 Chinook data We will illustrate the analysis of seasonal catch data using a data set of monthly chinook salmon from Washington state. Load the chinook salmon data set This is in the FishForecast package. require(FishForecast) head(chinook.month) (#tab:f80-load_packages) YearMonthSpeciesStatelog.metric.tonsmetric.tonsValue 1990JanChinookWA3.4&nbsp;29.91.09e+05 1990FebChinookWA3.8145.13.09e+05 1990MarChinookWA3.5133.52.01e+05 1990AprChinookWA4.2570&nbsp;&nbsp;4.31e+05 1990MayChinookWA5.2&nbsp;181&nbsp;&nbsp;8.6e+05&nbsp; 1990JunChinookWA4.3779.24.2e+05&nbsp; The data are monthly and start in January 1990. To make this into a ts object do chinookts &lt;- ts(chinook.month$log.metric.tons, start=c(1990,1), frequency=12) start is the year and month and frequency is the number of months in the year. If we had quarterly data that started in 2nd quarter of 1990, our call would be ts(chinook$log.metric.tons, start=c(1990,2), frequency=4) If we had daily data starting on hour 5 of day 10 and each row was an hour, our call would be ts(chinook$log.metric.tons, start=c(10,5), frequency=24) Use ?ts to see more examples of how to set up ts objects. Plot seasonal data Now that we have specified our seasonal data as a ts object, it is easy to plot because R knows what the season is. plot(chinookts) "],
["8-2-seasonal-exponential-smoothing-model.html", "8.2 Seasonal Exponential Smoothing Model", " 8.2 Seasonal Exponential Smoothing Model Now we add a few more lines to our ETS table of models: model “ZZZ” alternate function exponential smoothing no trend “ANN” ses() exponential smoothing with trend “AAN” holt() exponential smoothing with season no trend “ANA” NA exponential smoothing with season and trend “AAA” NA estimate best trend and season model “ZZZ” NA Unfortunately ets() will not handle missing values and will find the longest continuous piece of our data and use that. library(forecast) traindat &lt;- window(chinookts, c(1990,1), c(1999,12)) fit &lt;- forecast::ets(traindat, model=&quot;AAA&quot;) ## Warning in forecast::ets(traindat, model = &quot;AAA&quot;): Missing values encountered. ## Using longest contiguous portion of time series fr &lt;- forecast::forecast(fit, h=24) plot(fr) points(window(chinookts, c(1996,1), c(1996,12))) 8.2.1 Force seasonality to evolve more If we plot the decomposition, we see the the seasonal component is not changing over time, unlike the actual data. The bar on the right, alerts us that the scale on the 3rd panel is much smaller. autoplot(fit) Pass in a high gamma (the season weighting) to force the seasonality to evolve. fit &lt;- forecast::ets(traindat, model=&quot;AAA&quot;, gamma=0.4) ## Warning in forecast::ets(traindat, model = &quot;AAA&quot;, gamma = 0.4): Missing values ## encountered. Using longest contiguous portion of time series autoplot(fit) "],
["8-3-seasonal-arima-model.html", "8.3 Seasonal ARIMA model", " 8.3 Seasonal ARIMA model auto.arima() will recognize that our data has season and fit a seasonal ARIMA model to our data by default. Let’s use the data that ets() used. This is shorter than our training data and is Oct 1990 to Dec 1995. The data used by ets() is returned in fit$x. We will redefine the training data to be the longest segment with no missing values. traindat &lt;- window(chinookts, c(1990,10), c(1995,12)) testdat &lt;- window(chinookts, c(1996,1), c(1996,12)) fit &lt;- forecast::auto.arima(traindat) fr &lt;- forecast::forecast(fit, h=12) plot(fr) points(testdat) "],
["8-4-missing-values.html", "8.4 Missing values", " 8.4 Missing values Unlike for an exponential smoothing model, missing values are ok when fitting a seasonal ARIMA model fulldat &lt;- window(chinookts, c(1990,1), c(1999,12)) fit &lt;- forecast::auto.arima(fulldat) fr &lt;- forecast::forecast(fit, h=12) plot(fr) "],
["8-5-forecast-evaluation.html", "8.5 Forecast evaluation", " 8.5 Forecast evaluation We can compute the forecast performance metrics as usual. fit.ets &lt;- forecast::ets(traindat, model=&quot;AAA&quot;) fr &lt;- forecast::forecast(fit.ets, h=12) Look at the forecast so you know what years and months to include in your test data. Pull those 12 months out of your data using the window() function. testdat &lt;- window(chinookts, c(1996,1), c(1996,12)) Use accuracy() to get the forecast error metrics. forecast::accuracy(fr, testdat) ## ME RMSE MAE MPE MAPE MASE ## Training set -0.0001825075 0.5642326 0.4440532 -9.254074 25.40106 0.7364593 ## Test set 0.3143200919 0.7518660 0.6077172 65.753096 81.38568 1.0078949 ## ACF1 Theil&#39;s U ## Training set 0.07490341 NA ## Test set 0.05504107 0.4178409 We can do the same for the ARIMA model. fit &lt;- forecast::auto.arima(traindat) fr &lt;- forecast::forecast(fit, h=12) forecast::accuracy(fr, testdat) ## ME RMSE MAE MPE MAPE MASE ## Training set 0.01076412 0.5643352 0.3966735 -1.219729 26.91589 0.6578803 ## Test set 0.79665978 0.9180939 0.7966598 19.587692 53.48599 1.3212549 ## ACF1 Theil&#39;s U ## Training set -0.05991122 NA ## Test set -0.12306276 0.5993699 "],
["references.html", "References", " References Georgakarakos, S., D. Doutsoubas, and V. Valavanis. 2006. “Time Series Analysis and Forecasting Techniques Applied on Loliginid and Ommastrephid Landings in Greek Waters.” Journal Article. Fisheries Research 78: 55–71. Holmes, Eli, Eric Ward, Mark Scheuerell, Kellie Wills, NOAA, Seattle, and USA. 2020. MARSS: Multivariate Autoregressive State-Space Modeling. https://nwfsc-timeseries.github.io/MARSS. Hyndman, Rob, George Athanasopoulos, Christoph Bergmeir, Gabriel Caceres, Leanne Chhay, Mitchell O’Hara-Wild, Fotios Petropoulos, Slava Razbash, Earo Wang, and Farah Yasmeen. 2020. Forecast: Forecasting Functions for Time Series and Linear Models. https://CRAN.R-project.org/package=forecast. Lawer, Eric Adjei. 2016. “Empirical Modeling of Annual Fishery Landings.” Journal Article. Natural Resources 7: 193–204. Stergiou, K. I., and E. D. Christou. 1996. “Modeling and Forecasting Annual Fisheries Catches: Comparison of Regression, Univariate and Mulivariate Time Series Methods.” Journal Article. Fisheries Research 25 (2): 105–38. Stergiou, K. I., E. D. Christou, and G. Petrakis. 1997. “Modelling and Forecasting Monthly Fisheries Catches: Comparison of Regression, Univariate and Multivariate Time Series Methods.” Journal Article. Fisheries Research 29: 55–95. Trapletti, Adrian, and Kurt Hornik. 2019. Tseries: Time Series Analysis and Computational Finance. https://CRAN.R-project.org/package=tseries. Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2. "],
["A-inputting-data.html", "A Inputting data", " A Inputting data This chapter will illustrate how to input data that is stored in csv files in various common formats. one response variable If your data look like this: Year Species metric.tons 2018, Fish1, 1 2019, Fish1, 2 2018, Fish2, 3 2019, Fish2, 4 2018, Fish3, 6 2019, Fish4, NA with this code: test &lt;- read.csv(&quot;Data/test.csv&quot;, stringsAsFactors = FALSE) save(test, file=&quot;test.RData&quot;) Many response variables Read in a file where the data are in columns. If your data look like this with each species (or site) across the columns: Year,Anchovy,Sardine,Chub mackerel,Horse mackerel,Mackerel,Jack Mackerel 1964,5449.2,12984.4,1720.7,4022.4,NA,NA 1965,4263.5,10611.1,1278.5,4158.3,NA,NA 1966,5146.4,11437.8,802.6,3012.1,NA,NA Use this code: test &lt;- read.csv(&quot;Data/test.csv&quot;, stringsAsFactors = FALSE) reshape2::melt(test, id=&quot;Year&quot;, value.name=&quot;metric.tons&quot;, variable.name=&quot;Species&quot;) save(test, file=&quot;test.RData&quot;) Many response variables, two time variables If your data also have, say, a month (or qtr) column, use this code: Year,Month,Anchovy,Sardine,Chub mackerel,Horse mackerel,Mackerel,Jack Mackerel 1964,1,5449.2,12984.4,1720.7,4022.4,NA,NA 1964,2,4263.5,10611.1,1278.5,4158.3,NA,NA 1964,3,5146.4,11437.8,802.6,3012.1,NA,NA Use this code: test &lt;- read.csv(&quot;Data/test.csv&quot;, stringsAsFactors = FALSE) reshape2::melt(test, id=c(&quot;Year&quot;,&quot;Month&quot;), value.name=&quot;metric.tons&quot;, variable.name=&quot;Species&quot;) save(test, file=&quot;test.RData&quot;) One response variable, multiple explanatory variables Year, Anchovy, SST, Mackerel 1964, 5449.2, 24.4, 1720.7 1965, 4263.5, 30.1, 1278.5 1966, 5146.4, 23.8, 802.6 Use this code: test &lt;- read.csv(&quot;Data/test.csv&quot;, stringsAsFactors = FALSE) save(test, file=&quot;test.RData&quot;) Use this lm() model (or gam() etc): fit &lt;- lm(Anchovy ~ SST + Mackerel, data=test) "],
["B-downloading-icoads-covariates.html", "B Downloading ICOADS covariates", " B Downloading ICOADS covariates The covariates are those in Stergiou and Christou except that NS winds might not be vertical wind. I used the ICOADS data not the COADSs. The boxes are 1 degree but on 1 degree centers not 0.5 centers. Thus box is 39.5-40.5 not 39-40. The following is the code used to download the covariates from the NOAA ERDDAP server. It creates a list with the monthly data for each box. library(RCurl) library(XML) library(stringr) lat &lt;- c(39,39,40) lon &lt;- c(24,25,25) covs &lt;- list() for(i in 1:3){ loc &lt;- paste0(&quot;[(&quot;,lat[i],&quot;.5):1:(&quot;,lat[i],&quot;.5)][(&quot;,lon[i],&quot;.5):1:(&quot;,lon[i],&quot;.5)]&quot;) url &lt;- paste0(&quot;https://coastwatch.pfeg.noaa.gov/erddap/griddap/esrlIcoads1ge.htmlTable?air[(1964-01-01):1:(2018-08-01T00:00:00Z)]&quot;,loc,&quot;,slp[(1964-01-01):1:(2018-08-01T00:00:00Z)]&quot;,loc,&quot;,sst[(1964-01-01):1:(2018-08-01T00:00:00Z)]&quot;,loc,&quot;,vwnd[(1964-01-01):1:(2018-08-01T00:00:00Z)]&quot;,loc,&quot;,wspd3[(1964-01-01):1:(2018-08-01T00:00:00Z)]&quot;,loc) doc &lt;- getURL(url) cov &lt;- readHTMLTable(doc, which=2, stringsAsFactors=FALSE) coln &lt;- paste0(colnames(cov),&quot;.&quot;,cov[1,]) coln &lt;- str_replace(coln, &quot;\\n&quot;, &quot;&quot;) coln &lt;- str_replace_all(coln, &quot;[*]&quot;, &quot;&quot;) cov &lt;- cov[-1,] colnames(cov) &lt;- coln cov[,1] &lt;- as.Date(cov[,1]) for(j in 2:dim(cov)[2]) cov[,j] &lt;- as.numeric(cov[,j]) covs[[i]] &lt;- cov } Now create the monthly and yearly means. covsmean &lt;- covs[[1]] for(j in 2:dim(cov)[2]) covsmean[,j] &lt;- apply(cbind(covs[[1]][,j], covs[[2]][,j], covs[[3]][,j]),1,mean,na.rm=TRUE) covsmean &lt;- covsmean[,c(-2,-3)] covsmean$Year &lt;- as.factor(format(cov[,1],&quot;%Y&quot;)) covsmean.mon &lt;- covsmean covsmean.year &lt;- data.frame(Year=unique(covsmean$Year)) for(j in 2:(dim(covsmean)[2]-1)) covsmean.year &lt;- cbind(covsmean.year, tapply(covsmean[,j], covsmean$Year, mean, na.rm=TRUE)) colnames(covsmean.year) &lt;- c(&quot;Year&quot;,colnames(covsmean)[2:(dim(covsmean)[2]-1)]) "]
]
